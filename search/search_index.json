{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Medical-AI is an AI framework for rapid prototyping/experimentation of AI for Medical Applications </p> <p>Documentation: https://aibharata.github.io/medicalAI/</p> <p>Source Code: https://github.com/aibharata/medicalai</p> <p>Youtube Tutorial: </p> <p> </p> <p>Medical-AI is an AI framework  for rapid prototyping of AI for Medical Applications.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>$ pip install medicalai\n\n---&gt; 100%\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<p>Python Version : 3.5-3.7 (Doesn't Work on 3.8 Since Tensorflow does not support 3.8 yet.</p> <p>Dependencies: Numpy, Tensorflow, Seaborn, Matplotlib, Pandas</p> <pre><code>NOTE: Dependency libraries are automatically installed. No need for user to install them manually.\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#getting-started-tutorial-google-colab","title":"Getting Started Tutorial: Google Colab","text":"<p>Google Colab Notebook Link</p>"},{"location":"#importing-the-library","title":"Importing the Library","text":"<pre><code>import medicalai as ai\n</code></pre>"},{"location":"#using-templates","title":"Using Templates","text":"<p>You can use the following templates to perform specific Tasks</p>"},{"location":"#load-dataset-from-folder","title":"Load Dataset From Folder","text":"<p>Set the path of the dataset and set the target dimension of image that will be input to AI network. <pre><code>trainSet,testSet,labelNames =ai.datasetFromFolder(datasetFolderPath, targetDim = (96,96)).load_dataset()\n</code></pre>     - trainSet contains 'data' and 'labels' accessible by trainSet.data and trainSet.labels     - testSet contains 'data' and 'labels' accessible by testSet.data and testSet.labels     - labelNames contains class names/labels</p>"},{"location":"#check-loaded-dataset-size","title":"Check Loaded Dataset Size","text":"<pre><code>print(trainSet.data.shape)\nprint(trainSet.labels.shape)\n</code></pre>"},{"location":"#run-training-and-save-model","title":"Run Training and Save Model","text":"<pre><code>trainer = ai.TRAIN_ENGINE()\ntrainer.train_and_save_model(AI_NAME= 'tinyMedNet', MODEL_SAVE_NAME='PATH_WHERE_MODEL_IS_SAVED_TO', trainSet, testSet, OUTPUT_CLASSES, RETRAIN_MODEL= True, BATCH_SIZE= 32, EPOCHS= 10, LEARNING_RATE= 0.001)\n</code></pre>"},{"location":"#plot-training-loss-and-accuracy","title":"Plot Training Loss and Accuracy","text":"<pre><code>trainer.plot_train_acc_loss()\n</code></pre>"},{"location":"#generate-a-comprehensive-evaluation-pdf-report","title":"Generate a comprehensive evaluation PDF report","text":"<p><pre><code>trainer.generate_evaluation_report()\n</code></pre> PDF report will be generated with model sensitivity, specificity, accuracy, confidence intervals, ROC Curve Plot, Precision Recall Curve Plot, and Confusion Matrix Plot for each class. This function can be used when evaluating a model with Test or Validation Data Set.</p>"},{"location":"#explain-the-model-on-a-sample","title":"Explain the Model on a sample","text":"<pre><code>trainer.explain(testSet.data[0:1], layer_to_explain='CNN3')\n</code></pre>"},{"location":"#loading-model-for-prediction","title":"Loading Model for Prediction","text":"<pre><code>infEngine = ai.INFERENCE_ENGINE(modelName = 'PATH_WHERE_MODEL_IS_SAVED_TO')\n</code></pre>"},{"location":"#predict-with-labels","title":"Predict With Labels","text":"<pre><code>infEngine.predict_with_labels(testSet.data[0:2], top_preds=3)\n</code></pre>"},{"location":"#get-just-values-of-prediction-without-postprocessing","title":"Get Just Values of Prediction without postprocessing","text":"<pre><code>infEngine.predict(testSet.data[0:2])\n</code></pre>"},{"location":"#alternatively-use-a-faster-prediction-method-in-production","title":"Alternatively, use a faster prediction method in production","text":"<pre><code>infEngine.predict_pipeline(testSet.data[0:1])\n</code></pre>"},{"location":"#advanced-usage","title":"Advanced Usage","text":""},{"location":"#code-snippet-for-training-using-medical-ai","title":"Code snippet for Training Using Medical-AI","text":"<pre><code>## Setup AI Model Manager with required AI. \nmodel = ai.modelManager(AI_NAME= AI_NAME, modelName = MODEL_SAVE_NAME, x_train = train_data, OUTPUT_CLASSES = OUTPUT_CLASSES, RETRAIN_MODEL= RETRAIN_MODEL)\n\n# Start Training\nresult = ai.train(model, train_data, train_labels, BATCH_SIZE, EPOCHS, LEARNING_RATE, validation_data=(test_data, test_labels), callbacks=['tensorboard'])\n\n# Evaluate Trained Model on Test Data\nmodel.evaluate(test_data, test_labels)\n\n# Plot Accuracy vs Loss for Training\nai.plot_training_metrics(result)\n\n#Save the Trained Model\nai.save_model_and_weights(model, outputName= MODEL_SAVE_NAME)\n</code></pre>"},{"location":"#automated-tests","title":"Automated Tests","text":"<p>To Check the tests</p> <pre><code>    pytest\n</code></pre> <p>To See Output of Print Statements</p> <pre><code>    pytest -s\n</code></pre>"},{"location":"medicalai/core/","title":"medicalai.chief.core","text":""},{"location":"medicalai/core/#create_model_output_folder","title":"create_model_output_folder","text":"<pre><code>create_model_output_folder(outputName)\n</code></pre> <p>Creates model output folder if model doesn't exist.</p> <p>Arguments</p> <ul> <li>outputName: (Type - <code>filepath</code>): name of the folder where model needs to be created.</li> </ul> <p>Returns</p> <p><code>None</code>: None</p>"},{"location":"medicalai/core/#check_model_exists","title":"check_model_exists","text":"<pre><code>check_model_exists(outputName)\n</code></pre> <p>Checks if the given model's network file exists or not. Model name expected is <code>modelName + _arch.json</code>.</p> <p>Arguments</p> <ul> <li>outputName: (Type - <code>filepath</code>): model name to check.</li> </ul> <p>Returns</p> <p><code>Bool</code>: If model network exists returns <code>True</code> else <code>False</code>.</p>"},{"location":"medicalai/core/#save_model_and_weights","title":"save_model_and_weights","text":"<pre><code>save_model_and_weights(model, outputName)\n</code></pre> <p>Saves the passed model to MedicalAI Format. Accepts a model and converts to MedicalAI Format. Produces weight file (<code>outputName + _wgts.h5</code>) and network file (<code>outputName + _arch.json</code>)</p> <p>IMPORTANT</p> <p>DO NOT PASS ANY EXTENTION TO <code>outputName</code> argument</p> <p>Arguments</p> <ul> <li>model: (Type - <code>model</code> class): MedicalAI/Keras/Tensorflow 2.0+ model class.</li> <li>outputName: (Type - <code>filepath</code>): model path/name to save.</li> </ul> <p>Returns</p> <p><code>None</code>: None</p>"},{"location":"medicalai/core/#load_model_and_weights","title":"load_model_and_weights","text":"<pre><code>load_model_and_weights(modelName, summary=False)\n</code></pre> <p>Loads model from the given filepath. Function Expects weight file (<code>modelName + _wgts.h5</code>) and network file (<code>modelName + _arch.json</code>).</p> <p>NOTE</p> <p>DO NOT PASS ANY EXTENTION TO <code>outputName</code> argument</p> <p>For Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\nload_model_and_weights(modelName, summary = False)\n\nload_model_and_weights(modelName='devModel/testmodel1')\n\nload_model_and_weights('devModel/testmodel1', summary = True)\n</code></pre></p> <p>Arguments</p> <ul> <li>modelName: (Type - <code>filepath</code>): model path/name to save.</li> <li>summary: (Type - <code>Bool</code>): Show loaded network architecture and parameter summary.</li> </ul> <p>Returns</p> <p><code>model</code>: (Type - <code>model</code> class): MedicalAI/Keras/Tensorflow 2.0+ model class.</p>"},{"location":"medicalai/core/#modelmanager","title":"modelManager","text":"<pre><code>modelManager(modelName,\n             x_train,\n             OUTPUT_CLASSES,\n             RETRAIN_MODEL,\n             AI_NAME='tinyMedNet',\n             convLayers=None)\n</code></pre> <p>Model manager is used to build new model for given networks/AI or reload existing AI model. This function can be used to retrain existing models or create new models.</p> <p>IMPORTANT</p> <p>DO NOT PASS ANY EXTENTION TO <code>modelName</code> argument</p> <p>Arguments</p> <ul> <li>modelName: (Type - <code>filepath</code>): model path/name to load existing model or create new model.</li> <li>x_train: (Type - <code>numpy.array</code>): training dataset - expected shape [num_samples*dimension_of_input].</li> <li>OUTPUT_CLASSES: (Type - <code>Int</code>): Number of unique classes in dataset.</li> <li>RETRAIN_MODEL: (Type - <code>Bool</code>): Whether to retrain existing model. If set to <code>True</code> and model does not          exist, then it creates a new model and subsequent runs will retrain model.</li> <li>AI_NAME: (Type - <code>String</code> or <code>Custom Network Class</code>): Select AI Networks from existing catalogue in MedicalAI.          See AI_NAME Page for More Details.</li> <li>convLayers: (Type - <code>Int</code>): [Optional] Default is None. Only applicable for certain networks where convolution          layers are reconfigurable. This parameter can be used to change the num of conv          layers in Network. See AI_NAME Page for More Details.</li> </ul> <p>Returns</p> <p><code>model</code>: (Type - <code>model</code> class): MedicalAI/Keras/Tensorflow 2.0+ model class.</p> <p>See Also:  TRAIN_ENGINE, INFERENCE_ENGINE</p>"},{"location":"medicalai/core/#show_model_details","title":"show_model_details","text":"<pre><code>show_model_details(model)\n</code></pre> <p>Show model network structure and print parameters summary.</p> <p>Arguments</p> <ul> <li>model: (Type - <code>model</code> class): MedicalAI/Keras/Tensorflow 2.0+ model class.</li> </ul> <p>Returns</p> <p><code>None</code>: None; Prints the model summary</p>"},{"location":"medicalai/core/#predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(model,\n               input,\n               expected_output=None,\n               labelNames=None,\n               top_preds=4)\n</code></pre> <pre><code>predict_labels(model , input, expected_output = expected_output, labelNames=classNames,top_preds=4)\n</code></pre>"},{"location":"medicalai/core/#inference_engine","title":"INFERENCE_ENGINE","text":"<pre><code>INFERENCE_ENGINE(self, modelName=None, testSet=None, classNames=None)\n</code></pre> <p>Initializes Inference Engine to perform inference/prediction on a trained model. Can be used during production.</p> <p>Arguments</p> <ul> <li>modelName: (Type - <code>filepath</code>): model path/name to load existing model or create new model.</li> <li>testSet: (Type - <code>numpy.array</code> or <code>generator</code>): [Optional] : Test/Validation Dataset either as generator          or numpy array. Only passed if performing evaluation. No need to set          this during production.</li> <li>classNames: (Type - <code>list</code> or <code>numpy.array</code>): [Optional] : classNames or labelNames for the dataset.</li> </ul> <p>Returns</p> <p><code>INFERENCE_ENGINE Object</code>: If <code>modelName</code> is supplied, returns an object with loaded model.</p>"},{"location":"medicalai/core/#load_model_and_weights_1","title":"load_model_and_weights","text":"<pre><code>INFERENCE_ENGINE.load_model_and_weights(modelName, summary=False)\n</code></pre> <p>Loads model from the given filepath. Function Expects path to weight file (<code>modelName + _wgts.h5</code>) and network file (<code>modelName + _arch.json</code>).</p> <p>NOTE</p> <p>You can use <code>load_network</code> and <code>load_weights</code> if the model files are in MedicalAI Format.</p> <p>WARNING</p> <p>DO NOT PASS ANY EXTENTION TO <code>outputName</code> argument</p> <p>For Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_model_and_weights(modelName)\n\ninfEngine.load_model_and_weights(modelName, summary = True)\n</code></pre></p> <p>Arguments</p> <ul> <li>modelName: (Type - <code>filepath</code>): model path/name to load.</li> <li>summary: (Type - <code>Bool</code>): [Optional] : <code>Default = False</code>. Show loaded network architecture         and parameter summary.</li> </ul> <p>Returns</p> <p><code>None</code>: Intializes Object with model.</p>"},{"location":"medicalai/core/#load_network","title":"load_network","text":"<pre><code>INFERENCE_ENGINE.load_network(fileName)\n</code></pre> <p>Loads network from given filepath. Function Expects path to network file with <code>.json</code> extension.</p> <p>NOTE</p> <p>Use this function only if the model files are not in MedicalAI Format.</p> <p>Example: <pre><code>networkFile = 'devModel/testmodel1.json'\n\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_network(networkFile)\n</code></pre></p> <p>Arguments</p> <ul> <li>modelName: (Type - <code>filepath</code>): model network path/name to load. File should have <code>.json</code> extension.</li> </ul> <p>Returns</p> <p><code>None</code>: Intializes Object with model network initialized. After this model weights can be loaded.</p>"},{"location":"medicalai/core/#load_weights","title":"load_weights","text":"<pre><code>INFERENCE_ENGINE.load_weights(wgtfileName)\n</code></pre> <p>Loads weight from given filepath. Function Expects path to weight file with <code>.h5</code> extension.</p> <p>NOTE</p> <p>Use this function only if the model files are not in MedicalAI Format.  Before calling this function, network needs to loaded using <code>load_network</code> function.</p> <p>Example: <pre><code>networkFile = 'devModel/testmodel1.json'\nwgtFile = 'devModel/testmodel1.h5'\n\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_network(networkFile)\ninfEngine.load_weights(wgtFile)\n</code></pre></p> <p>Arguments</p> <ul> <li>wgtfileName: (Type - <code>filepath</code>): model weight filepath/name to load. File should have <code>.h5</code> extension.</li> </ul> <p>Returns</p> <p><code>None</code>: Intializes Object with model loaded with weights.</p>"},{"location":"medicalai/core/#preprocessor_from_meta","title":"preprocessor_from_meta","text":"<pre><code>INFERENCE_ENGINE.preprocessor_from_meta(metaFile=None)\n</code></pre> <p>Loads preprocessor parameter and initializes preprocessor from meta file generated by MedicalAI.</p> <p>If the model is trained using this framework, then the metafile is automatically available and initialized.</p> <p>WARNING</p> <p>If model is not trained using this framework, then one can use this engine by creating metafile  similar to one generated by this framework. Please see repo for more details.</p> <p>Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_model_and_weights(modelName)\n\n# There is no need to perform this op if model trained using this framework. It is automatically Initialized.\n# There is no need to pass modelName if the model is trained using framework\ninfEngine.preprocessor_from_meta()\n\ninfEngine.preprocessor_from_meta(metaFile='myMetaFile.json') [`Else`](#Else) pass the metafile\n</code></pre></p> <p>Arguments</p> <ul> <li>metaFile: (Type - <code>filepath</code>): [Optional] : if no parameter is passed, then it will look for          <code>modelname + _meta.json</code> file. If modelname is set during          INFERENCE_ENGINE initialization, then it automatically handles this.</li> </ul> <p>Returns</p> <p><code>None</code>: Intializes Object with Preprocessor into process pipeline.</p>"},{"location":"medicalai/core/#predict","title":"predict","text":"<pre><code>INFERENCE_ENGINE.predict(input)\n</code></pre> <p>Peform prediction on Input. Input can be Numpy Array or Image or Data Generator (in case of Test/Validation).</p> <p>Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\n\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_model_and_weights(modelName)\ninfEngine.preprocessor_from_meta()\n\n# Predict an input image\ninfEngine.predict(input = 'test.jpg')\n</code></pre></p> <p>Arguments</p> <ul> <li>input: (Type - <code>numpy.array</code>|<code>imagePath</code>|<code>generator</code> ): Can be single image file or numpy array of multiple          images or data generator class.</li> </ul> <p>Returns</p> <p><code>Numpy.Array</code>: of Predictions. Shape of Output [Number of Inputs, Number of Output Classes in Model]</p>"},{"location":"medicalai/core/#predict_pipeline","title":"predict_pipeline","text":"<pre><code>INFERENCE_ENGINE.predict_pipeline(input)\n</code></pre> <p>Slightly Faster version of predict. Useful for deployment. Do not use <code>INFERENCE_ENGINE.predict</code> in production. Peform prediction on Input. Input can be Numpy Array or Image or Data Generator (in case of Test/Validation).</p> <p>Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\n\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_model_and_weights(modelName)\ninfEngine.preprocessor_from_meta()\n\n# Predict an input image\ninfEngine.predict_pipeline(input = 'test.jpg')\n</code></pre></p> <p>Arguments</p> <ul> <li>input: (Type - <code>numpy.array</code>|<code>imagePath</code>|<code>generator</code> ): Can be single image file or numpy array of multiple          images or data generator class.</li> </ul> <p>Returns</p> <p><code>Numpy.Array</code>: of Predictions. Shape of Output [Number of Inputs, Number of Output Classes in Model]</p>"},{"location":"medicalai/core/#decode_predictions","title":"decode_predictions","text":"<pre><code>INFERENCE_ENGINE.decode_predictions(pred, top_preds=4, retType='tuple')\n</code></pre> <p>Returns Decodes predictions with label/class names with output probabilites. During production this can be used to return a json serializable dictionary instead of tuple.</p> <p>Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\n\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_model_and_weights(modelName)\ninfEngine.preprocessor_from_meta()\n\n# Predict an input image\npred = infEngine.predict_pipeline(input = 'test.jpg')\npred_tuple = infEngine.decode_predictions(pred, top_preds=2)\n\n# Get a json serializable dictionary instead of tuple\npred_dict  = infEngine.decode_predictions(pred, top_preds=2, retType = 'dict')\n</code></pre></p> <p>Arguments</p> <ul> <li>pred: (Type - <code>numpy.array</code>): Prediction output of either <code>INFERENCE_ENGINE.predict</code> or          <code>INFERENCE_ENGINE.predict_pipleline</code>.</li> <li>top_preds: (Type - <code>Integer</code>): [Optional] : <code>Default = 4</code> - Number of top prediction to return. If the number is           set to higher than number of classes in network, it returns all predictions.</li> <li>retType: (Type - <code>String</code>): [Optional] : <code>Default = tuple</code>. Options - [<code>dict</code> or <code>tuple</code>]. <code>Dict</code> helpful in production.</li> </ul> <p>Returns</p> <p><code>Tuple or Dict</code>: of Predictions with probabilities. Shape of Output [Number of Inputs, Max(top_preds,Number of Output Classes in Model)]</p>"},{"location":"medicalai/core/#getlayernames","title":"getLayerNames","text":"<pre><code>INFERENCE_ENGINE.getLayerNames()\n</code></pre> <p>Get the layer names of the network. Useful for when using Explainable-AI function as it expects <code>layer name</code> as argument.</p> <p>Example: <pre><code># If Model files are `devModel/testmodel1_wgts.h5` and `devModel/testmodel1_arch.json`\n# Then `modelName=devModel/testmodel1`\n\nmodelName = 'devModel/testmodel1'\n\ninfEngine = INFERENCE_ENGINE()\ninfEngine.load_model_and_weights(modelName)\n\n# Print the Layer Names\nprint('\n'.join(infEngine.getLayerNames()))\n</code></pre></p>"},{"location":"medicalai/core/#summary","title":"summary","text":"<pre><code>INFERENCE_ENGINE.summary()\n</code></pre> <p>Show model network structure and print parameters summary.</p> <p>Arguments</p> <ul> <li>None: None</li> </ul> <p>Returns</p> <p><code>None</code>: None; Prints the model summary</p>"},{"location":"medicalai/core/#generate_evaluation_report","title":"generate_evaluation_report","text":"<pre><code>INFERENCE_ENGINE.generate_evaluation_report(testSet=None,\n                                            predictions=None,\n                                            printStat=False,\n                                            returnPlot=False,\n                                            showPlot=False,\n                                            pdfName=None,\n                                            **kwargs)\n</code></pre> <p>Generate a comprehensive PDF report with model sensitivity, specificity, accuracy, confidence intervals, ROC Curve Plot, Precision Recall Curve Plot, and Confusion Matrix Plot for each class. This function can be used when evaluating a model with Test or Validation Data Set.</p> <p>Example:</p> <pre><code># Load Dataset\ntrainSet,testSet,labelNames =ai.datasetFromFolder(datasetFolderPath, targetDim = (224,224)).load_dataset()\n\n# Intialize Inference Engine\ninfEngine = ai.INFERENCE_ENGINE(MODEL_SAVE_NAME)\n\n# Preform Prediction on DataSet\npredsG = infEngine.predict(testSet.data)\n\n# Generate Report\ninfEngine.generate_evaluation_report(testSet,predictions = predsG , pdfName = \"expt_evaluation_report.pdf\")\n</code></pre> <p>Alternatively: <pre><code># Load Dataset\ntrainSet,testSet,labelNames =ai.datasetFromFolder(datasetFolderPath, targetDim = (224,224)).load_dataset()\n\n# Intialize Inference Engine\ninfEngine = ai.INFERENCE_ENGINE(MODEL_SAVE_NAME)\n\n# Generate Report - If predictions are not passed, then automatically prediction is performed.\ninfEngine.generate_evaluation_report(testSet, pdfName = \"expt_evaluation_report.pdf\")\n</code></pre> Arguments</p> <ul> <li>testSet: (Type - <code>numpy.array</code> or <code>generator</code>) : Test Data Set to perform evaluation on.</li> <li>predictions: (Type - <code>numpy.array</code>): [Optional] : Prediction output of either <code>INFERENCE_ENGINE.predict</code> or          <code>INFERENCE_ENGINE.predict_pipleline</code>. If this parameter is not set, then prediction          is perfomred internally and evaluation report is generated.</li> <li>pdfName: (Type - <code>Bool</code>): [Optional] : <code>Default = ModelName + _report.pdf</code> - Pdf Output Name.</li> <li>printStat: (Type - <code>Bool</code>): [Optional] : <code>Default = False</code> - Print Statistics on console.</li> <li>returnPlot: (Type - <code>Bool</code>): [Optional] : <code>Default = False</code> - Return Plot Figure Handle.</li> <li>showPlot: (Type - <code>Bool</code>): [Optional] : <code>Default = False</code> - Show Plot figure.</li> </ul> <p>Returns</p> <p><code>None or Plot Handle</code>: If <code>returnPlot = True</code> then Plot Handle will be returned else None.</p>"},{"location":"medicalai/core/#explain","title":"explain","text":"<pre><code>INFERENCE_ENGINE.explain(input,\n                         predictions=None,\n                         layer_to_explain='CNN3',\n                         classNames=None,\n                         selectedClasses=None,\n                         expectedClass=None,\n                         showPlot=False)\n</code></pre> <p>Explains a model layer with respect to Input and Output using Grad-cam. Basically, see what the AI is seeing to arrive at a certain prediction. More methods to be updated in next versions.</p> <pre><code># Load a sample\nimage = load(Image)\n\n# Intialize Inference Engine\ninfEngine = ai.INFERENCE_ENGINE(MODEL_SAVE_NAME)\n\n# Print Layer Names\nprint('\n'.join(infEngine.getLayerNames()))\n\n# If predictions are not passed, then automatically prediction is performed. You can perform prediction first then pass\n  to the below function. Pass one of the layer name from above output to `layer_to_explain`.\ninfEngine.explain(image, layer_to_explain='CNN3')\n</code></pre> <p>Arguments</p> <ul> <li>input: (Type - <code>numpy.array</code> or <code>image</code>) : Input to perform explanation on. For safety, pass single or few samples only.</li> <li>predictions: (Type - <code>numpy.array</code>): [Optional] : Prediction output of either <code>INFERENCE_ENGINE.predict</code> or          <code>INFERENCE_ENGINE.predict_pipleline</code>. If this parameter is not set, then prediction          is perfomred internally and explanation is generated.</li> <li>layer_to_explain: (Type - <code>String</code>):  Layer to explain.</li> <li>classNames: (Type - <code>Numpy.Array</code> or <code>List</code>): [Optional] : <code>Default = None| Loaded from Meta File</code> - Class Names or Label Names of Dataset.</li> <li>selectedClasses: (Type - <code>Bool</code>): [Optional] : <code>Default = None</code> - Explain only few subset of Class Names. If <code>None</code> then all classes will be explained.</li> <li>expectedClass: (Type - <code>Bool</code>): [Optional] : <code>Default = None</code> - Expected Label/Class Name for the Input.</li> </ul> <p>Returns</p> <p><code>None</code>: Shows a plot figure with explanations.</p>"},{"location":"medicalai/core/#train_engine","title":"TRAIN_ENGINE","text":"<pre><code>TRAIN_ENGINE(self, modelName=None)\n</code></pre> <p>Initializes Training Engine to perform training/prediction. TRAIN_ENGINE is a superclass of INFERENCE_ENGINE. Meaning, all the methods and functions of INFERENCE_ENGINE are available with TRAIN_ENGINE with additional methods of its own.</p> <p>Arguments</p> <ul> <li>modelName: (Type - <code>filepath</code>): [Optional] model path/name to load existing model or create new model.</li> </ul> <p>Returns</p> <p><code>TRAIN_ENGINE Object</code>: Ready to Train a given dataset.</p>"},{"location":"medicalai/core/#train_and_save_model","title":"train_and_save_model","text":"<p><pre><code>TRAIN_ENGINE.train_and_save_model(AI_NAME,\n                                  MODEL_SAVE_NAME,\n                                  trainSet,\n                                  testSet,\n                                  OUTPUT_CLASSES,\n                                  RETRAIN_MODEL,\n                                  BATCH_SIZE,\n                                  EPOCHS,\n                                  LEARNING_RATE,\n                                  convLayers=None,\n                                  SAVE_BEST_MODEL=False,\n                                  BEST_MODEL_COND=None,\n                                  callbacks=None,\n                                  loss='sparse_categorical_crossentropy',\n                                  metrics=['accuracy'],\n                                  showModel=False,\n                                  CLASS_WEIGHTS=None)\n</code></pre> \" Main function that trains and saves a model. This automatically builds new model for given networks/AI or reload existing AI model. This function can be used to retrain existing models or create new models.</p> <p>IMPORTANT</p> <p>DO NOT PASS ANY EXTENTION TO <code>MODEL_SAVE_NAME</code> argument</p> <p>USAGE:</p> <pre><code># Set Parameters\nAI_NAME = 'MobileNet_X'\nMODEL_SAVE_NAME = 'testModel1'\n\nOUTPUT_CLASSES = 10\nRETRAIN_MODEL = True\nEPOCHS = 10\nBATCH_SIZE = 32\nLEARNING_RATE = 0.0001\nSAVE_BEST_MODEL = False\nBEST_MODEL_COND = None\ncallbacks = None\n\n# Initialize Train Engine\ntrainer = ai.TRAIN_ENGINE()\n\n# Train and Save Model\ntrainer.train_and_save_model(AI_NAME=AI_NAME,                                                       # AI/Network to Use\n       MODEL_SAVE_NAME = MODEL_SAVE_NAME,                                       # Target MODEL To Save/Load/Retrain\n       trainSet=trainGen, testSet=testGen, OUTPUT_CLASSES=OUTPUT_CLASSES,       # From Dataset Loader\n       RETRAIN_MODEL= RETRAIN_MODEL, BATCH_SIZE= BATCH_SIZE, EPOCHS= EPOCHS,    # Training Settings\n       SAVE_BEST_MODEL = SAVE_BEST_MODEL,   BEST_MODEL_COND= BEST_MODEL_COND,   # Early Stopping Settings\n       loss='categorical_crossentropy',                                     # Loss Function\n       showModel = False,                                                       # Show Network Summary\n       callbacks = callbacks,                                                   # Additional/Advanced Hooks\n       )\n</code></pre> <p>Arguments</p> <ul> <li>AI_NAME: (Type - <code>string</code> or <code>NetworkInit() class</code>): Select Network from catalogue (string) or create your own network and pass the class.</li> <li>MODEL_SAVE_NAME: (Type - <code>filepath</code>): [Optional] model path/name to load existing model or create new model.</li> <li>trainSet: (Type - <code>numpy.array</code> or <code>generator</code>): [Optional] : Training Dataset either as generator or numpy array from <code>DataLoader</code> class.</li> <li>testSet: (Type - <code>numpy.array</code> or <code>generator</code>): [Optional] : Test/Validation Dataset either as generator or numpy array       from <code>DataLoader</code> class.</li> <li>OUTPUT_CLASSES: (Type - <code>Int</code>): Number of unique classes in dataset.</li> <li>RETRAIN_MODEL: (Type - <code>Bool</code>): Whether to retrain existing model. If set to True and model does not exist,       then it creates a new model and subsequent runs will retrain model.</li> <li>BATCH_SIZE: (Type - <code>Int</code>): Batch size for Training. If Training fails when using large datasets, try reducing this number.</li> <li>EPOCHS: (Type - <code>Int</code>): Number of Epochs to train.</li> <li>LEARNING_RATE: (Type - <code>Float</code>): [Optional] : Set Learning rate. If not set, optimizer default will be used.</li> <li>convLayers: (Type - <code>Int</code>): [Optional] Default is None. Only applicable for certain networks where convolution          layers are reconfigurable. This parameter can be used to change the num of conv          layers in Network. See AI_NAME Page for More Details.</li> <li>SAVE_BEST_MODEL: (Type - <code>Bool</code>): [Optional] : <code>Default: False</code> - Initializes Training Engine with saving best model feature.</li> <li>BEST_MODEL_COND: (Type - <code>String</code> or <code>Dict</code>): [Optional] : <code>Default: None</code> - Initializes Training Engine with early stopping feature.      [Options] -&gt; <code>Default</code> or <code>Dict</code>.</li> <li>Dict Values Expected:</li> <li>'monitor': (Type - <code>String</code>): Which Parameter to Monitor. [Options] -&gt; ('val_accuracy', 'val_loss', 'accuracy'),</li> <li>'min_delta': (Type - <code>Float</code>): minimum change in the monitored quantity to qualify as an improvement,        i.e. an absolute change of less than min_delta, will count as no improvement.</li> <li>'patience': (Type - <code>Int</code>): number of epochs with no improvement after which training will be stopped.</li> <li>loss: (Type - <code>String</code>) : <code>Default: sparse_categorical_crossentropy</code>, Loss function to apply. Depends on dataprocessor.         If dataloaders has one-hot encoded labels then use <code>sparse_categorical_crossentropy</code> else if         labers are encoded then -&gt; <code>categorical_crossentropy</code>.</li> <li>metrics: (Type - <code>List</code>): [Optional] : <code>Default: ['accuracy']</code>. Metrics to Monitor during Training.</li> <li>showModel: (Type - <code>Bool</code>): [Optional] : Whether to show the network summary before start of training.</li> <li>CLASS_WEIGHTS: (Type - <code>Dict</code>) [Optional] : Dictionary containing class weights for model.fit()</li> <li>callbacks: (Type - <code>Tensorflow Callbacks</code>): Tensorflow Callbacks can be attacked.</li> </ul> <p>Returns</p> <p><code>None</code>: On successful completion saves the trained model.</p>"},{"location":"medicalai/core/#plot_train_acc_loss","title":"plot_train_acc_loss","text":"<pre><code>TRAIN_ENGINE.plot_train_acc_loss()\n</code></pre> <p>Plot training accuracy and loss graph vs epoch. Generates an interactive graph for inspection.</p> <p>USAGE:</p> <p><pre><code># Set Parameters\nAI_NAME = 'MobileNet_X'\nMODEL_SAVE_NAME = 'testModel1'\n\nOUTPUT_CLASSES = 10\nRETRAIN_MODEL = True\nEPOCHS = 10\nBATCH_SIZE = 32\nLEARNING_RATE = 0.0001\nSAVE_BEST_MODEL = False\nBEST_MODEL_COND = None\ncallbacks = None\n\n# Initialize Train Engine\ntrainer = ai.TRAIN_ENGINE()\n\n# Train and Save Model\ntrainer.train_and_save_model(AI_NAME=AI_NAME,                                                       # AI/Network to Use\n       MODEL_SAVE_NAME = MODEL_SAVE_NAME,                                       # Target MODEL To Save/Load/Retrain\n       trainSet=trainGen, testSet=testGen, OUTPUT_CLASSES=OUTPUT_CLASSES,       # From Dataset Loader\n       RETRAIN_MODEL= RETRAIN_MODEL, BATCH_SIZE= BATCH_SIZE, EPOCHS= EPOCHS,    # Training Settings\n       SAVE_BEST_MODEL = SAVE_BEST_MODEL,   BEST_MODEL_COND= BEST_MODEL_COND,   # Early Stopping Settings\n       loss='categorical_crossentropy',                                     # Loss Function\n       showModel = False,                                                       # Show Network Summary\n       callbacks = callbacks,                                                   # Additional/Advanced Hooks\n       )\n\ntrainer.plot_training_metrics()\n</code></pre> Arguments</p> <ul> <li>None: None</li> </ul> <p>Returns</p> <p><code>None</code>: Opens accuracy vs loss vs epoch plot.</p>"},{"location":"medicalai/dataset_processors/","title":"medicalai.chief.dataset_prepare","text":""},{"location":"medicalai/dataset_processors/#datasetfromfolder","title":"datasetFromFolder","text":"<pre><code>datasetFromFolder(self,\n                  folder,\n                  targetDim=(31, 31),\n                  normalize=False,\n                  name=None,\n                  useCache=True,\n                  forceCleanCache=False)\n</code></pre> <p>TODO: Fix samplingMethodName assignment</p>"},{"location":"medicalai/dataset_processors/#datasetgenfromfolder","title":"datasetGenFromFolder","text":"<pre><code>datasetGenFromFolder(self,\n                     folder,\n                     targetDim=(224, 224),\n                     normalize=False,\n                     batch_size=16,\n                     augmentation=True,\n                     color_mode='rgb',\n                     class_mode='sparse',\n                     shuffle=True,\n                     seed=23)\n</code></pre> <p>Create a dataset generator from dataset present in Folder. The folder should consist of <code>test</code> and <code>train</code> folders and each of the folders should have <code>n</code> classes of folders.</p> <p>Arguments</p> <ul> <li>folder: The directory must be set to the path where your <code>n</code> classes of folders are present.</li> <li>targetDim: The target_size is the size of your input images to the neural network.</li> <li>class_mode: Set <code>binary</code> if classifying only two classes, if not set to <code>categorical</code>, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to <code>input</code>.</li> <li>color_mode: <code>grayscale</code> for black and white or grayscale, <code>rgb</code> for three color channels.</li> <li>batch_size: Number of images to be yielded from the generator per batch. If training fails lower this number.</li> <li>augmentation: : [Optional] : <code>Default = True</code>: Perform augmentation on Dataset</li> <li>shuffle: : [Optional] : <code>Default = True</code>: Shuffle Dataset</li> <li>seed: : [Optional] : <code>Default = 23</code>: Initialize Random Seed</li> </ul> <p>Returns</p> <p><code>None</code>: Initializes Test and Train Data Generators</p>"},{"location":"medicalai/dataset_processors/#datasetgenfromdataframe","title":"datasetGenFromDataframe","text":"<p><pre><code>datasetGenFromDataframe(self,\n                        folder,\n                        csv_path='.',\n                        x_col='name',\n                        y_col='labels',\n                        targetDim=(224, 224),\n                        normalize=False,\n                        batch_size=16,\n                        augmentation=True,\n                        color_mode='rgb',\n                        class_mode='sparse',\n                        shuffle=True,\n                        seed=17)\n</code></pre> Creates Keras Dataset Generator for Handling Large Datasets from DataFrame.</p> <p>Arguments</p> <ul> <li>csv_path: folder containing train.csv and test.csv.</li> <li>folder: The directory must be set to the path where your training images are present.</li> <li>x_col: Name of column containing image name, <code>default = name</code>.</li> <li>y_col: Name of column for labels, <code>default = labels</code>.</li> <li>targetDim: The target_size is the size of your input images to the neural network.</li> <li>class_mode: Set <code>binary</code> if classifying only two classes, if not set to <code>categorical</code>, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to <code>input</code>.</li> <li>color_mode: <code>grayscale</code> for black and white or grayscale, <code>rgb</code> for three color channels.</li> <li>batch_size: Number of images to be yielded from the generator per batch. If training fails lower this number.</li> <li>augmentation: : [Optional] : <code>Default = True</code>: Perform augmentation on Dataset</li> <li>shuffle: : [Optional] : <code>Default = True</code>: Shuffle Dataset</li> <li>seed: : [Optional] : <code>Default = 23</code>: Initialize Random Seed</li> </ul> <p>Returns</p> <p><code>None</code>: Initializes Test and Train Data Generators</p>"},{"location":"medicalai/medicalai.chief/","title":"medicalai.chief package","text":""},{"location":"medicalai/medicalai.chief/#subpackages","title":"Subpackages","text":"<ul> <li> <p>medicalai.chief.model_metrics package</p> <ul> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.model_metrics.modelstats module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> <li> <p>medicalai.chief.nnets package</p> <ul> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.nnets.covid_net module</p> </li> <li> <p>medicalai.chief.nnets.densenet module</p> </li> <li> <p>medicalai.chief.nnets.inceptionResnet module</p> </li> <li> <p>medicalai.chief.nnets.inceptionv3 module</p> </li> <li> <p>medicalai.chief.nnets.mobilenet module</p> </li> <li> <p>medicalai.chief.nnets.mobilenetv2 module</p> </li> <li> <p>medicalai.chief.nnets.resnet module</p> </li> <li> <p>medicalai.chief.nnets.vgg16 module</p> </li> <li> <p>medicalai.chief.nnets.xception module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> <li> <p>medicalai.chief.xai package</p> <ul> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.xai.xcams module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief/#submodules","title":"Submodules","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcore-module","title":"medicalai.chief.core module","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefcoreinference_enginemodelname-testsetnone-classnamesnone","title":"class medicalai.chief.core.INFERENCE_ENGINE(modelName, testSet=None, classNames=None)","text":"<p>Bases: <code>object</code></p> <p>TODO: Need to add Metaloader support</p>"},{"location":"medicalai/medicalai.chief/#decode_predictionspred-top_preds4-rettypetuple","title":"decode_predictions(pred, top_preds=4, retType='tuple')","text":""},{"location":"medicalai/medicalai.chief/#explaininput-predictionsnone-layer_to_explaincnn3-classnamesnone-selectedclassesnone-expectedclassnone-showplotfalse","title":"explain(input, predictions=None, layer_to_explain='CNN3', classNames=None, selectedClasses=None, expectedClass=None, showPlot=False)","text":""},{"location":"medicalai/medicalai.chief/#generate_evaluation_reporttestsetnone-predictionsnone-printstatfalse-returnplotfalse-showplotfalse-pdfnamenone-kwargs","title":"generate_evaluation_report(testSet=None, predictions=None, printStat=False, returnPlot=False, showPlot=False, pdfName=None, **kwargs)","text":""},{"location":"medicalai/medicalai.chief/#getlayernames","title":"getLayerNames()","text":""},{"location":"medicalai/medicalai.chief/#load_model_and_weightsmodelname","title":"load_model_and_weights(modelName)","text":""},{"location":"medicalai/medicalai.chief/#load_networkfilename","title":"load_network(fileName)","text":""},{"location":"medicalai/medicalai.chief/#load_weightswgtfilename","title":"load_weights(wgtfileName)","text":""},{"location":"medicalai/medicalai.chief/#predictinput","title":"predict(input)","text":""},{"location":"medicalai/medicalai.chief/#predict_pipelineinput","title":"predict_pipeline(input)","text":"<p>Slightly Faster version of predict. Useful for deployment.</p>"},{"location":"medicalai/medicalai.chief/#preprocessor_from_metametafilenone","title":"preprocessor_from_meta(metaFile=None)","text":""},{"location":"medicalai/medicalai.chief/#summary","title":"summary()","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefcoretrain_enginemodelnamenone","title":"class medicalai.chief.core.TRAIN_ENGINE(modelName=None)","text":"<p>Bases: <code>medicalai.chief.core.INFERENCE_ENGINE</code></p>"},{"location":"medicalai/medicalai.chief/#plot_train_acc_loss","title":"plot_train_acc_loss()","text":""},{"location":"medicalai/medicalai.chief/#train_and_save_modelai_name-model_save_name-trainset-testset-output_classes-retrain_model-batch_size-epochs-learning_rate-convlayersnone-save_best_modeltrue-best_model_condnone-callbacksnone-losssparse_categorical_crossentropy-metricsaccuracy-showmodelfalse-class_weightsnone","title":"train_and_save_model(AI_NAME, MODEL_SAVE_NAME, trainSet, testSet, OUTPUT_CLASSES, RETRAIN_MODEL, BATCH_SIZE, EPOCHS, LEARNING_RATE, convLayers=None, SAVE_BEST_MODEL=True, BEST_MODEL_COND=None, callbacks=None, loss='sparse_categorical_crossentropy', metrics=['accuracy'], showModel=False, CLASS_WEIGHTS=None)","text":"<p>\u201d CLASS_WEIGHTS: Dictionary containing class weights for model.fit()</p>"},{"location":"medicalai/medicalai.chief/#medicalaichiefcorecheck_model_existsoutputname","title":"medicalai.chief.core.check_model_exists(outputName)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcorecreate_model_output_folderoutputname","title":"medicalai.chief.core.create_model_output_folder(outputName)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcoredecode_predictionspred-labelnames-top_preds4-rettypetuple","title":"medicalai.chief.core.decode_predictions(pred, labelNames, top_preds=4, retType='tuple')","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcoreload_model_and_weightsmodelname-summaryfalse","title":"medicalai.chief.core.load_model_and_weights(modelName, summary=False)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcoremodelmanagermodelname-x_train-output_classes-retrain_model-ai_nametinymednet-convlayersnone","title":"medicalai.chief.core.modelManager(modelName, x_train, OUTPUT_CLASSES, RETRAIN_MODEL, AI_NAME='tinyMedNet', convLayers=None)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcoreplot_training_metricsresult-themelight","title":"medicalai.chief.core.plot_training_metrics(result, theme='light')","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcorepredict_labelsmodel-input-expected_outputnone-labelnamesnone-top_preds4","title":"medicalai.chief.core.predict_labels(model, input, expected_output=None, labelNames=None, top_preds=4)","text":"<p>predict(x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)</p>"},{"location":"medicalai/medicalai.chief/#medicalaichiefcoresave_model_and_weightsmodel-outputname","title":"medicalai.chief.core.save_model_and_weights(model, outputName)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcoreshow_model_detailsmodel","title":"medicalai.chief.core.show_model_details(model)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefcoretrainmodel-x_train-batch_size1-epochs1-learning_rate0001-callbacksnone-class_weightsnone-savebestmodelfalse-bestmodelcondnone-validation_datanone-train_stepsnone-test_stepsnone-losssparse_categorical_crossentropy-metricsaccuracy-verbosenone-y_trainnone","title":"medicalai.chief.core.train(model, x_train, batch_size=1, epochs=1, learning_rate=0.001, callbacks=None, class_weights=None, saveBestModel=False, bestModelCond=None, validation_data=None, TRAIN_STEPS=None, TEST_STEPS=None, loss='sparse_categorical_crossentropy', metrics=['accuracy'], verbose=None, y_train=None)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_prepare-module","title":"medicalai.chief.dataset_prepare module","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_prepareaugmentationrotation_range12-fill_modeconstant-width_shift_range01-height_shift_range01-horizontal_flipfalse-vertical_flipfalse-brightness_range09-11-zoom_range085-115-rescale000392156862745098-shear_range0-channel_shift_range0-samplewise_centerfalse-samplewise_std_normalizationfalse-featurewise_centerfalse-featurewise_std_normalizationfalse-cval0-preprocessing_functionnone","title":"class medicalai.chief.dataset_prepare.AUGMENTATION(rotation_range=12, fill_mode='constant', width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=False, vertical_flip=False, brightness_range=(0.9, 1.1), zoom_range=(0.85, 1.15), rescale=0.00392156862745098, shear_range=0, channel_shift_range=0, samplewise_center=False, samplewise_std_normalization=False, featurewise_center=False, featurewise_std_normalization=False, cval=0, preprocessing_function=None)","text":"<p>Bases: <code>object</code></p>"},{"location":"medicalai/medicalai.chief/#create_aug","title":"create_aug()","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_prepareinput_processortargetdim31-31-samplingmethodnone-normalizefalse-color_modergb-rescalenone-dtypefloat32","title":"class medicalai.chief.dataset_prepare.INPUT_PROCESSOR(targetDim=(31, 31), samplingMethod=None, normalize=False, color_mode='RGB', rescale=None, dtype='float32')","text":"<p>Bases: <code>object</code></p>"},{"location":"medicalai/medicalai.chief/#processimageimage","title":"processImage(image)","text":""},{"location":"medicalai/medicalai.chief/#resizedatasetdataset","title":"resizeDataSet(dataset)","text":""},{"location":"medicalai/medicalai.chief/#resizedatasetfromfolderfolder","title":"resizeDataSetfromFolder(folder)","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_prepareinputprocessorfrommetametafile","title":"class medicalai.chief.dataset_prepare.InputProcessorFromMeta(metaFile)","text":"<p>Bases: <code>medicalai.chief.dataset_prepare.INPUT_PROCESSOR</code></p>"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_prepareconvertlist2tuplelst","title":"medicalai.chief.dataset_prepare.convertlist2tuple(lst)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparedatasetfolderstructurevalidatefolder","title":"medicalai.chief.dataset_prepare.datasetFolderStructureValidate(folder)","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetfromfolderfolder-targetdim31-31-normalizefalse-namenone-usecachetrue-forcecleancachefalse","title":"class medicalai.chief.dataset_prepare.datasetFromFolder(folder, targetDim=(31, 31), normalize=False, name=None, useCache=True, forceCleanCache=False)","text":"<p>Bases: <code>medicalai.chief.dataset_prepare.datasetManager</code></p> <p>TODO: Fix samplingMethodName assignment</p>"},{"location":"medicalai/medicalai.chief/#load_dataset","title":"load_dataset()","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetgenfromdataframefolder-csv_path-x_colname-y_collabels-targetdim224-224-normalizefalse-batch_size16-augmentationtrue-color_modergb-class_modesparse-shuffletrue-seed17","title":"class medicalai.chief.dataset_prepare.datasetGenFromDataframe(folder, csv_path='.', x_col='name', y_col='labels', targetDim=(224, 224), normalize=False, batch_size=16, augmentation=True, color_mode='rgb', class_mode='sparse', shuffle=True, seed=17)","text":"<p>Bases: <code>object</code></p> <p>Creates Keras Dataset Generator for Handling Large Datasets from DataFrame.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>csv_path \u2013 folder containing train.csv and test.csv.</p> </li> <li> <p>folder \u2013 The directory must be set to the path where your training images are present.</p> </li> <li> <p>x_col \u2013 Name of column containing image name, default = name.</p> </li> <li> <p>y_col \u2013 Name of column for labels, default = labels.</p> </li> <li> <p>targetDim \u2013 The target_size is the size of your input images to the neural network.</p> </li> <li> <p>class_mode \u2013 Set binary if classifying only two classes, if not set to categorical, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input.</p> </li> <li> <p>color_mode \u2013 grayscale for black and white or grayscale, rgb for three color channels.</p> </li> <li> <p>batch_size \u2013 Number of images to be yielded from the generator per batch. If training fails lower this number.</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief/#get_class_weights","title":"get_class_weights()","text":""},{"location":"medicalai/medicalai.chief/#get_numpygenerator","title":"get_numpy(generator)","text":""},{"location":"medicalai/medicalai.chief/#load_generator","title":"load_generator()","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetgenfromfolderfolder-targetdim224-224-normalizefalse-batch_size16-augmentationtrue-color_modergb-class_modesparse-shuffletrue-seed17","title":"class medicalai.chief.dataset_prepare.datasetGenFromFolder(folder, targetDim=(224, 224), normalize=False, batch_size=16, augmentation=True, color_mode='rgb', class_mode='sparse', shuffle=True, seed=17)","text":"<p>Bases: <code>object</code></p> <p>folder : The directory must be set to the path where your n classes of folders are present. targetDim : The target_size is the size of your input images to the neural network. class_mode : Set binary if classifying only two classes, if not set to categorical, in case of an Autoencoder system, both input and the output would probably be the same image, for this case set to input. color_mode: grayscale for black and white or grayscale, rgb for three color channels. batch_size: Number of images to be yielded from the generator per batch. If training fails lower this number.</p>"},{"location":"medicalai/medicalai.chief/#get_class_weights_1","title":"get_class_weights()","text":""},{"location":"medicalai/medicalai.chief/#get_numpygenerator_1","title":"get_numpy(generator)","text":""},{"location":"medicalai/medicalai.chief/#load_generator_1","title":"load_generator()","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparedatasetmanagerfolder-targetdim31-31-normalizefalse-namenone-usecachetrue-forcecleancachefalse","title":"class medicalai.chief.dataset_prepare.datasetManager(folder, targetDim=(31, 31), normalize=False, name=None, useCache=True, forceCleanCache=False)","text":"<p>Bases: <code>medicalai.chief.dataset_prepare.INPUT_PROCESSOR</code></p>"},{"location":"medicalai/medicalai.chief/#compress_and_cache_datakw","title":"compress_and_cache_data(**kw)","text":""},{"location":"medicalai/medicalai.chief/#convert_datasetkw","title":"convert_dataset(**kw)","text":""},{"location":"medicalai/medicalai.chief/#load_data","title":"load_data()","text":""},{"location":"medicalai/medicalai.chief/#process_dataset","title":"process_dataset()","text":""},{"location":"medicalai/medicalai.chief/#reload_datakw","title":"reload_data(**kw)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparedatasetmanagerfuncfolder-targetdim31-31-normalizefalse","title":"medicalai.chief.dataset_prepare.datasetManagerFunc(folder, targetDim=(31, 31), normalize=False)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparegetlabelsfromfolderfolder","title":"medicalai.chief.dataset_prepare.getLabelsFromFolder(folder)","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparemedicalai_generator","title":"class medicalai.chief.dataset_prepare.medicalai_generator()","text":"<p>Bases: <code>tensorflow.python.keras.preprocessing.image.ImageDataGenerator</code></p>"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparemetaloadermetafile","title":"medicalai.chief.dataset_prepare.metaLoader(metaFile)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparemetasaverlabelmap-labels-normalizenone-rescalenone-network_input_dimnone-samplingmethodnamenone-outputnamenone","title":"medicalai.chief.dataset_prepare.metaSaver(labelMap, labels, normalize=None, rescale=None, network_input_dim=None, samplingMethodName=None, outputName=None)","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdataset_preparemydict","title":"class medicalai.chief.dataset_prepare.myDict()","text":"<p>Bases: <code>dict</code></p>"},{"location":"medicalai/medicalai.chief/#medicalaichiefdataset_preparesafe_labelmap_converterlabelmap","title":"medicalai.chief.dataset_prepare.safe_labelmap_converter(labelMap)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utils-module","title":"medicalai.chief.download_utils module","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefdownload_utilsdlprogressiterablenone-descnone-totalnone-leavetrue-filenone-ncolsnone-mininterval01-maxinterval100-minitersnone-asciinone-disablefalse-unitit-unit_scalefalse-dynamic_ncolsfalse-smoothing03-bar_formatnone-initial0-positionnone-postfixnone-unit_divisor1000-write_bytesnone-guifalse-kwargs","title":"class medicalai.chief.download_utils.DLProgress(iterable=None, desc=None, total=None, leave=True, file=None, ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None, ascii=None, disable=False, unit='it', unit_scale=False, dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0, position=None, postfix=None, unit_divisor=1000, write_bytes=None, gui=False, **kwargs)","text":"<p>Bases: <code>tqdm._tqdm.tqdm</code></p>"},{"location":"medicalai/medicalai.chief/#hookblock_num1-block_size1-total_sizenone","title":"hook(block_num=1, block_size=1, total_size=None)","text":""},{"location":"medicalai/medicalai.chief/#last_block-0","title":"last_block( = 0)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilscheck_if_urlx","title":"medicalai.chief.download_utils.check_if_url(x)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsgetfileurl-storepathnone-cachedirnone-subdirdataset","title":"medicalai.chief.download_utils.getFile(url, storePath=None, cacheDir=None, subDir='dataset')","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsload_imagelink-target_size32-32-storepathnone-cachedirnone-subdirimages","title":"medicalai.chief.download_utils.load_image(link, target_size=(32, 32), storePath=None, cacheDir=None, subDir='images')","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsuntartar_file-destination","title":"medicalai.chief.download_utils.untar(tar_file, destination)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefdownload_utilsunzipzip_file-destination","title":"medicalai.chief.download_utils.unzip(zip_file, destination)","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefnetworks-module","title":"medicalai.chief.networks module","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksdensenet121","title":"class medicalai.chief.networks.DenseNet121()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>DenseNet121 model, with weights pre-trained on ImageNet inputSize: input image size tuple outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksinceptionresnetv2","title":"class medicalai.chief.networks.InceptionResNetV2()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>InceptionResNetV2 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_1","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksinceptionv3","title":"class medicalai.chief.networks.InceptionV3()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>InceptionV3 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_2","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksmobilenet","title":"class medicalai.chief.networks.MobileNet()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_3","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksmobilenetv2","title":"class medicalai.chief.networks.MobileNetV2()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_4","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksnetworkinit","title":"class medicalai.chief.networks.NetworkInit()","text":"<p>Bases: <code>object</code></p> <p>Base class for parameter Network initializers.</p> <p>The <code>NetworkInit</code> class represents a network initializer used to initialize network/model parameters for numerous medical ai networks. It should be subclassed when implementing new types of network initializers.</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_5","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksvgg16","title":"class medicalai.chief.networks.VGG16()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>VGG16 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_6","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksxception","title":"class medicalai.chief.networks.Xception()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>Xception model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_7","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#medicalaichiefnetworksgetnetworkinitialization","title":"medicalai.chief.networks.get(networkInitialization)","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksmeganet","title":"class medicalai.chief.networks.megaNet()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>megaNet is based on COVID-NET. This is a tensorflow 2.0 network variant for COVID-Net described in Paper \u201cCOVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\u201d by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_8","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet110","title":"class medicalai.chief.networks.resNet110()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>resnet110</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_9","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet20","title":"class medicalai.chief.networks.resNet20()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>resnet20</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_10","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet32","title":"class medicalai.chief.networks.resNet32()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>resnet32</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_11","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworksresnet56","title":"class medicalai.chief.networks.resNet56()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>RESNET56</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_12","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworkstinymednet","title":"class medicalai.chief.networks.tinyMedNet()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>tinyMedNet is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayersnone_13","title":"call(inputSize, OutputSize, convLayers=None)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworkstinymednet_v2","title":"class medicalai.chief.networks.tinyMedNet_v2()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>tinyMedNet_v2 allows users to configure the number of Conv/CNN layers. tinyMedNet_v2 is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayers2","title":"call(inputSize, OutputSize, convLayers=2)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#class-medicalaichiefnetworkstinymednet_v3","title":"class medicalai.chief.networks.tinyMedNet_v3()","text":"<p>Bases: <code>medicalai.chief.networks.NetworkInit</code></p> <p>tinyMedNet_v3 has 3 FC layers with Dropout and Configurable number of Conv/CNN Layers.</p>"},{"location":"medicalai/medicalai.chief/#callinputsize-outputsize-convlayers2_1","title":"call(inputSize, OutputSize, convLayers=2)","text":"<p>Sample should return model initialized with input and output Sizes.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>inputSize (tuple** or **int.) \u2013 Integer or tuple specifying the input of network.</p> </li> <li> <p>OutputSize (tuple** or **int.) \u2013 Integer or tuple specifying the output classes of network.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Initialized Model.</p> </li> <li> <p>Return type</p> <p>numpy.array.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief/#medicalaichiefprettyloss-module","title":"medicalai.chief.prettyloss module","text":""},{"location":"medicalai/medicalai.chief/#class-medicalaichiefprettylossprettylossshow_percentagefalse","title":"class medicalai.chief.prettyloss.prettyLoss(show_percentage=False)","text":"<p>Bases: <code>object</code></p>"},{"location":"medicalai/medicalai.chief/#style-bold-x1b1m-green-x1b32m-red-x1b91m","title":"STYLE( = {'bold': '\\x1b[1m', 'green': '\\x1b[32m', 'red': '\\x1b[91m'})","text":""},{"location":"medicalai/medicalai.chief/#style_end-x1b0m","title":"STYLE_END( = '\\x1b[0m')","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefufuncs-module","title":"medicalai.chief.uFuncs module","text":""},{"location":"medicalai/medicalai.chief/#medicalaichiefufuncstimeitfunc","title":"medicalai.chief.uFuncs.timeit(func)","text":""},{"location":"medicalai/medicalai.chief/#module-contents","title":"Module contents","text":""},{"location":"medicalai/medicalai.chief.model_metrics/","title":"medicalai.chief.model_metrics package","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#submodules","title":"Submodules","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstats-module","title":"medicalai.chief.model_metrics.modelstats module","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsbootstrap_aucy-pred-classes-bootstraps100-fold_size1000","title":"medicalai.chief.model_metrics.modelstats.bootstrap_auc(y, pred, classes, bootstraps=100, fold_size=1000)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsclassify_reporty_true-y_pred","title":"medicalai.chief.model_metrics.modelstats.classify_report(y_true, y_pred)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatscompute_class_freqslabels","title":"medicalai.chief.model_metrics.modelstats.compute_class_freqs(labels)","text":"<p>Compute positive and negative frequences for each class.</p> <ul> <li> <p>Parameters</p> <p>labels (np.array) \u2013 matrix of labels, size (num_examples, num_classes)</p> </li> <li> <p>Returns</p> <p>array of positive frequences for each</p> <pre><code>class, size (num_classes)\n</code></pre> <p>negative_frequencies (np.array): array of negative frequences for each</p> <pre><code>class, size (num_classes)\n</code></pre> </li> <li> <p>Return type</p> <p>positive_frequencies (np.array)</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsconfidence_intervalsclass_labels-statistics","title":"medicalai.chief.model_metrics.modelstats.confidence_intervals(class_labels, statistics)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsfalse_negativesexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.false_negatives(expected, preds, threshold=0.5)","text":"<p>Count false positives.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>pred (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>false negatives</p> </li> <li> <p>Return type</p> <p>false_neg (int)</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsfalse_positivesexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.false_positives(expected, preds, threshold=0.5)","text":"<p>Count false positives.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>false positives</p> </li> <li> <p>Return type</p> <p>false_pos (int)</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsgenerate_evaluation_reportclass_names-predictions-groundtruthnone-generatornone-returnplottrue-showplottrue-printstattrue-kwargs","title":"medicalai.chief.model_metrics.modelstats.generate_evaluation_report(CLASS_NAMES, predictions, groundTruth=None, generator=None, returnPlot=True, showPlot=True, printStat=True, **kwargs)","text":"<p>Generates Evaluation PDF Report for a Test/Validation experimentation. Ground truth needs to be passed to generate the pdf report.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>CLASS_NAMES (list) \u2013 List of Label names or class names of dataset.</p> </li> <li> <p>predictions (np.array) \u2013 Predicted output of test data.</p> </li> <li> <p>groundTruth (np.array) \u2013 Ground truth of test data.</p> </li> <li> <p>generator (Optional) \u2013 If generator method used in training, pass the generator.</p> </li> <li> <p>returnPlot (Bool) \u2013 Returns the plot handle if set to True</p> </li> <li> <p>showPlot (Bool) \u2013 Display the plot if set to True. [IMP: Until the plot is closed, the code execution is blocked.]</p> </li> <li> <p>printStat (Bool) \u2013 Print the statistics of the experiment on the console if set to True. T</p> </li> <li> <p>**kwargs (Optional) \u2013 Plot Setting Arguments</p> </li> </ul> </li> <li> <p>Returns</p> <p>true positives</p> </li> <li> <p>Return type</p> <p>true_pos (int)</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_accuracyexpected-preds-threshold09","title":"medicalai.chief.model_metrics.modelstats.get_accuracy(expected, preds, threshold=0.9)","text":"<p>Compute accuracy of predictions at threshold.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>accuracy of predictions at threshold</p> </li> <li> <p>Return type</p> <p>accuracy (float)</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_accuracy_scoretest_labels-test_predictions","title":"medicalai.chief.model_metrics.modelstats.get_accuracy_score(test_labels, test_predictions)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_curvegt-pred-target_names-curveroc-returnplotfalse-showplottrue-axesnone-kwargs","title":"medicalai.chief.model_metrics.modelstats.get_curve(gt, pred, target_names, curve='roc', returnPlot=False, showPlot=True, axes=None, **kwargs)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_false_negy-pred-th05","title":"medicalai.chief.model_metrics.modelstats.get_false_neg(y, pred, th=0.5)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_false_posy-pred-th05","title":"medicalai.chief.model_metrics.modelstats.get_false_pos(y, pred, th=0.5)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_npvexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.get_npv(expected, preds, threshold=0.5)","text":"<p>Compute NPV of predictions at threshold.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>negative predictive value of predictions at threshold</p> </li> <li> <p>Return type</p> <p>NPV (float)</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_performance_metricsy-pred-class_labels-tp-tn-fp-fn-accnone-prevalencenone-specnone-sensnone-ppvnone-npvnone-aucnone-f1none-thresholds","title":"medicalai.chief.model_metrics.modelstats.get_performance_metrics(y, pred, class_labels, tp=, tn=, fp=, fn=, acc=None, prevalence=None, spec=None, sens=None, ppv=None, npv=None, auc=None, f1=None, thresholds=[])","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_ppvexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.get_ppv(expected, preds, threshold=0.5) <p>Compute PPV of predictions at threshold.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>positive predictive value of predictions at threshold</p> </li> <li> <p>Return type</p> <p>PPV (float)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_prevalenceexpected","title":"medicalai.chief.model_metrics.modelstats.get_prevalence(expected) <p>Compute accuracy of predictions at threshold.</p> <ul> <li> <p>Parameters</p> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>Returns</p> <p>prevalence of positive cases</p> </li> <li> <p>Return type</p> <p>prevalence (float)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_roc_curvelabels-predicted_vals-groundtruthnone-generatornone-returnplotfalse-showplottrue-axesnone-kwargs","title":"medicalai.chief.model_metrics.modelstats.get_roc_curve(labels, predicted_vals, groundTruth=None, generator=None, returnPlot=False, showPlot=True, axes=None, **kwargs)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_sensitivityexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.get_sensitivity(expected, preds, threshold=0.5) <p>Compute sensitivity of predictions at threshold.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>probability that our test outputs positive given that the case is actually positive</p> </li> <li> <p>Return type</p> <p>sensitivity (float)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_specificityexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.get_specificity(expected, preds, threshold=0.5) <p>Compute specificity of predictions at threshold.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>probability that the test outputs negative given that the case is actually negative</p> </li> <li> <p>Return type</p> <p>specificity (float)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_true_negy-pred-th05","title":"medicalai.chief.model_metrics.modelstats.get_true_neg(y, pred, th=0.5)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_true_posy-pred-th05","title":"medicalai.chief.model_metrics.modelstats.get_true_pos(y, pred, th=0.5)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsget_weighted_losspos_weights-neg_weights-epsilon1e-07","title":"medicalai.chief.model_metrics.modelstats.get_weighted_loss(pos_weights, neg_weights, epsilon=1e-07) <p>Return weighted loss function given negative weights and positive weights.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>pos_weights (np.array) \u2013 array of positive weights for each class, size (num_classes)</p> </li> <li> <p>neg_weights (np.array) \u2013 array of negative weights for each class, size (num_classes)</p> </li> </ul> </li> <li> <p>Returns</p> <p>weighted loss function</p> </li> <li> <p>Return type</p> <p>weighted_loss (function)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsmodel_performance_metricsy-pred-class_labels-tp-tn-fp-fn-thresholds","title":"medicalai.chief.model_metrics.modelstats.model_performance_metrics(y, pred, class_labels, tp=, tn=, fp=, fn=, thresholds=[])","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsplatt_scalingy-pred-class_labels","title":"medicalai.chief.model_metrics.modelstats.platt_scaling(y, pred, class_labels)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsplot_calibration_curvey-pred-class_labels","title":"medicalai.chief.model_metrics.modelstats.plot_calibration_curve(y, pred, class_labels)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsplot_confusion_matrixmodelnone-test_datanone-test_labelsnone-labelnamesnone-titleconfusion-matrix-predictionsnone-showplottrue-returnplotfalse","title":"medicalai.chief.model_metrics.modelstats.plot_confusion_matrix(model=None, test_data=None, test_labels=None, labelNames=None, title='Confusion Matrix', predictions=None, showPlot=True, returnPlot=False)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsprint_classification_reporty_true-y_pred","title":"medicalai.chief.model_metrics.modelstats.print_classification_report(y_true, y_pred)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsprint_cohen_kappa_scorey_true-y_pred","title":"medicalai.chief.model_metrics.modelstats.print_cohen_kappa_score(y_true, y_pred)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatsrender_df_as_tabledata-titletable-col_width30-row_height0625-font_size18-header_color655ee5-row_colorsf1f1f2-w-edge_colorw-bbox0-0-1-1-header_columns0-resetindexfalse-axnone-kwargs","title":"medicalai.chief.model_metrics.modelstats.render_df_as_table(data, title='Table', col_width=3.0, row_height=0.625, font_size=18, header_color='#655EE5', row_colors=['#f1f1f2', 'w'], edge_color='w', bbox=[0, 0, 1, 1], header_columns=0, resetIndex=False, ax=None, **kwargs)","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatstrue_negativesexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.true_negatives(expected, preds, threshold=0.5) <p>Count true negatives.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>true negatives</p> </li> <li> <p>Return type</p> <p>true_neg (int)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#medicalaichiefmodel_metricsmodelstatstrue_positivesexpected-preds-threshold05","title":"medicalai.chief.model_metrics.modelstats.true_positives(expected, preds, threshold=0.5) <p>Count true positives.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>expected (np.array) \u2013 ground truth, size (n_examples)</p> </li> <li> <p>preds (np.array) \u2013 model output, size (n_examples)</p> </li> <li> <p>threshold (float) \u2013 cutoff value for positive prediction from model</p> </li> </ul> </li> <li> <p>Returns</p> <p>true positives</p> </li> <li> <p>Return type</p> <p>true_pos (int)</p> </li> </ul>","text":""},{"location":"medicalai/medicalai.chief.model_metrics/#module-contents","title":"Module contents","text":""},{"location":"medicalai/medicalai.chief.nnets/","title":"medicalai.chief.nnets package","text":""},{"location":"medicalai/medicalai.chief.nnets/#submodules","title":"Submodules","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetscovid_net-module","title":"medicalai.chief.nnets.covid_net module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetscovid_netcovidnet_kerasimg_input224-224-3-classes4","title":"medicalai.chief.nnets.covid_net.COVIDNET_Keras(img_input=(224, 224, 3), classes=4)","text":"<p>This is a tensorflow 2.0 network variant for COVID-Net described in Paper \u201cCOVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\u201d by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/</p>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetscovid_netpepxmodelinput_tensor-filters-name","title":"medicalai.chief.nnets.covid_net.PEPXModel(input_tensor, filters, name)","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsdensenet-module","title":"medicalai.chief.nnets.densenet module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsdensenetdensenet121_modelimg_input224-224-3-classes3","title":"medicalai.chief.nnets.densenet.DenseNet121_Model(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the DenseNet121 network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionresnet-module","title":"medicalai.chief.nnets.inceptionResnet module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionresnetinceptionresnetv2_modelimg_input224-224-3-classes3","title":"medicalai.chief.nnets.inceptionResnet.InceptionResNetV2_Model(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the InceptionResNetV2 network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionv3-module","title":"medicalai.chief.nnets.inceptionv3 module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsinceptionv3inceptionv3img_input224-224-3-classes3","title":"medicalai.chief.nnets.inceptionv3.InceptionV3(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the InceptionV3 network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenet-module","title":"medicalai.chief.nnets.mobilenet module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenetmobilenetimg_input224-224-3-classes3","title":"medicalai.chief.nnets.mobilenet.MobileNet(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the MobileNet network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenetv2-module","title":"medicalai.chief.nnets.mobilenetv2 module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsmobilenetv2mobilenetv2img_input224-224-3-classes3","title":"medicalai.chief.nnets.mobilenetv2.MobileNetV2(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the MobileNetV2 network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnet-module","title":"medicalai.chief.nnets.resnet module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetconv_building_blockinput_tensor-kernel_size-filters-stage-block-strides2-2-trainingnone","title":"medicalai.chief.nnets.resnet.conv_building_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), training=None)","text":"<p>A block that has a conv layer at shortcut.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>input_tensor \u2013 input tensor</p> </li> <li> <p>kernel_size \u2013 default 3, the kernel size of middle conv layer at main path</p> </li> <li> <p>filters \u2013 list of integers, the filters of 3 conv layer at main path</p> </li> <li> <p>stage \u2013 integer, current stage label, used for generating layer names</p> </li> <li> <p>block \u2013 current block label, used for generating layer names</p> </li> <li> <p>strides \u2013 Strides for the first conv layer in the block.</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other scenarios it is handled automatically.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Output tensor for the block.</p> </li> </ul> <p>Note that from stage 3, the first conv layer at main path is with strides=(2, 2) And the shortcut should have strides=(2, 2) as well</p>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetidentity_building_blockinput_tensor-kernel_size-filters-stage-block-trainingnone","title":"medicalai.chief.nnets.resnet.identity_building_block(input_tensor, kernel_size, filters, stage, block, training=None)","text":"<p>The identity block is the block that has no conv layer at shortcut.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>input_tensor \u2013 input tensor</p> </li> <li> <p>kernel_size \u2013 default 3, the kernel size of middle conv layer at main path</p> </li> <li> <p>filters \u2013 list of integers, the filters of 3 conv layer at main path</p> </li> <li> <p>stage \u2013 integer, current stage label, used for generating layer names</p> </li> <li> <p>block \u2013 current block label, used for generating layer names</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other scenarios it is handled automatically.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Output tensor for the block.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnetnum_blocks-img_inputnone-classes10-trainingnone","title":"medicalai.chief.nnets.resnet.resnet(num_blocks, img_input=None, classes=10, training=None)","text":"<p>Instantiates the ResNet architecture.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2)</p> </li> <li> <p>classes \u2013 optional number of classes to classify images into</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other</p> </li> <li> <p>it is handled automatically. (scenarios) \u2013 </p> </li> </ul> </li> <li> <p>Returns</p> <p>A Keras model instance.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet110-num_blocks110-img_inputnone-classes10-trainingnone","title":"medicalai.chief.nnets.resnet.resnet110(*, num_blocks=110, img_input=None, classes=10, training=None)","text":"<p>Instantiates the ResNet architecture.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2)</p> </li> <li> <p>classes \u2013 optional number of classes to classify images into</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other</p> </li> <li> <p>it is handled automatically. (scenarios) \u2013 </p> </li> </ul> </li> <li> <p>Returns</p> <p>A Keras model instance.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet20-num_blocks3-img_inputnone-classes10-trainingnone","title":"medicalai.chief.nnets.resnet.resnet20(*, num_blocks=3, img_input=None, classes=10, training=None)","text":"<p>Instantiates the ResNet architecture.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2)</p> </li> <li> <p>classes \u2013 optional number of classes to classify images into</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other</p> </li> <li> <p>it is handled automatically. (scenarios) \u2013 </p> </li> </ul> </li> <li> <p>Returns</p> <p>A Keras model instance.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet32-num_blocks5-img_inputnone-classes10-trainingnone","title":"medicalai.chief.nnets.resnet.resnet32(*, num_blocks=5, img_input=None, classes=10, training=None)","text":"<p>Instantiates the ResNet architecture.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2)</p> </li> <li> <p>classes \u2013 optional number of classes to classify images into</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other</p> </li> <li> <p>it is handled automatically. (scenarios) \u2013 </p> </li> </ul> </li> <li> <p>Returns</p> <p>A Keras model instance.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet56-num_blocks9-img_inputnone-classes10-trainingnone","title":"medicalai.chief.nnets.resnet.resnet56(*, num_blocks=9, img_input=None, classes=10, training=None)","text":"<p>Instantiates the ResNet architecture.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>num_blocks \u2013 integer, the number of conv/identity blocks in each block. The ResNet contains 3 blocks with each block containing one conv block followed by (layers_per_block - 1) number of idenity blocks. Each conv/idenity block has 2 convolutional layers. With the input convolutional layer and the pooling layer towards the end, this brings the total size of the network to (6*num_blocks + 2)</p> </li> <li> <p>classes \u2013 optional number of classes to classify images into</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other</p> </li> <li> <p>it is handled automatically. (scenarios) \u2013 </p> </li> </ul> </li> <li> <p>Returns</p> <p>A Keras model instance.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsresnetresnet_blockinput_tensor-size-kernel_size-filters-stage-conv_strides2-2-trainingnone","title":"medicalai.chief.nnets.resnet.resnet_block(input_tensor, size, kernel_size, filters, stage, conv_strides=(2, 2), training=None)","text":"<p>A block which applies conv followed by multiple identity blocks.</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>input_tensor \u2013 input tensor</p> </li> <li> <p>size \u2013 integer, number of constituent conv/identity building blocks.</p> </li> <li> <p>conv block is applied once**, ****followed by** (A) \u2013 </p> </li> <li> <p>kernel_size \u2013 default 3, the kernel size of middle conv layer at main path</p> </li> <li> <p>filters \u2013 list of integers, the filters of 3 conv layer at main path</p> </li> <li> <p>stage \u2013 integer, current stage label, used for generating layer names</p> </li> <li> <p>conv_strides \u2013 Strides for the first conv layer in the block.</p> </li> <li> <p>training \u2013 Only used if training keras model with Estimator.  In other scenarios it is handled automatically.</p> </li> </ul> </li> <li> <p>Returns</p> <p>Output tensor after applying conv and identity blocks.</p> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsvgg16-module","title":"medicalai.chief.nnets.vgg16 module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsvgg16vgg16_modelimg_input224-224-3-classes3","title":"medicalai.chief.nnets.vgg16.VGG16_Model(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the VGG16 network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsxception-module","title":"medicalai.chief.nnets.xception module","text":""},{"location":"medicalai/medicalai.chief.nnets/#medicalaichiefnnetsxceptionxceptionimg_input224-224-3-classes3","title":"medicalai.chief.nnets.xception.Xception(img_input=(224, 224, 3), classes=3)","text":"<p>Loaded the Xception network, ensuring the head FC layer sets are left off</p> <ul> <li> <p>Parameters</p> <ul> <li> <p>img_input \u2013 optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \u2018channels_last\u2019 data format) or (3, 224, 224) (with \u2018channels_first\u2019 data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.</p> </li> <li> <p>classes \u2013 Number of classes to be predicted.</p> </li> <li> <p>Returns \u2013 model</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai.chief.nnets/#module-contents","title":"Module contents","text":""},{"location":"medicalai/medicalai.chief.xai/","title":"medicalai.chief.xai package","text":""},{"location":"medicalai/medicalai.chief.xai/#submodules","title":"Submodules","text":""},{"location":"medicalai/medicalai.chief.xai/#medicalaichiefxaixcams-module","title":"medicalai.chief.xai.xcams module","text":""},{"location":"medicalai/medicalai.chief.xai/#medicalaichiefxaixcamspredict_with_gradcammodel-imgnp-labels-selected_labels-layer_namebn-expectednone-predictionsnone-showplotfalse","title":"medicalai.chief.xai.xcams.predict_with_gradcam(model, imgNP, labels, selected_labels, layer_name='bn', expected=None, predictions=None, showPlot=False)","text":"<p>TODO: Explainer requires model to sent for every call. This may be expensive.</p> <pre><code>Need to find a way to Initialize the model or share with predict engine.\nElse the memory required may double.\n</code></pre>"},{"location":"medicalai/medicalai.chief.xai/#module-contents","title":"Module contents","text":""},{"location":"medicalai/medicalai/","title":"medicalai package","text":""},{"location":"medicalai/medicalai/#subpackages","title":"Subpackages","text":"<ul> <li> <p>medicalai.chief package</p> <ul> <li> <p>Subpackages</p> <ul> <li> <p>medicalai.chief.model_metrics package</p> <ul> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.model_metrics.modelstats module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> <li> <p>medicalai.chief.nnets package</p> <ul> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.nnets.covid_net module</p> </li> <li> <p>medicalai.chief.nnets.densenet module</p> </li> <li> <p>medicalai.chief.nnets.inceptionResnet module</p> </li> <li> <p>medicalai.chief.nnets.inceptionv3 module</p> </li> <li> <p>medicalai.chief.nnets.mobilenet module</p> </li> <li> <p>medicalai.chief.nnets.mobilenetv2 module</p> </li> <li> <p>medicalai.chief.nnets.resnet module</p> </li> <li> <p>medicalai.chief.nnets.vgg16 module</p> </li> <li> <p>medicalai.chief.nnets.xception module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> <li> <p>medicalai.chief.xai package</p> <ul> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.xai.xcams module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> </ul> </li> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.core module</p> </li> <li> <p>medicalai.chief.dataset_prepare module</p> </li> <li> <p>medicalai.chief.download_utils module</p> </li> <li> <p>medicalai.chief.networks module</p> </li> <li> <p>medicalai.chief.prettyloss module</p> </li> <li> <p>medicalai.chief.uFuncs module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> </ul>"},{"location":"medicalai/medicalai/#module-contents","title":"Module contents","text":""},{"location":"medicalai/modelStats/","title":"medicalai.chief.model_metrics.modelstats","text":""},{"location":"medicalai/modelStats/#true_positives","title":"true_positives","text":"<pre><code>true_positives(expected, preds, threshold=0.5)\n</code></pre> <p>Count true positives.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>true_pos (int): true positives\n</code></pre>"},{"location":"medicalai/modelStats/#true_negatives","title":"true_negatives","text":"<pre><code>true_negatives(expected, preds, threshold=0.5)\n</code></pre> <p>Count true negatives.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>true_neg (int): true negatives\n</code></pre>"},{"location":"medicalai/modelStats/#false_positives","title":"false_positives","text":"<pre><code>false_positives(expected, preds, threshold=0.5)\n</code></pre> <p>Count false positives.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>false_pos (int): false positives\n</code></pre>"},{"location":"medicalai/modelStats/#false_negatives","title":"false_negatives","text":"<pre><code>false_negatives(expected, preds, threshold=0.5)\n</code></pre> <p>Count false positives.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npred (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>false_neg (int): false negatives\n</code></pre>"},{"location":"medicalai/modelStats/#get_accuracy","title":"get_accuracy","text":"<pre><code>get_accuracy(expected, preds, threshold=0.9)\n</code></pre> <p>Compute accuracy of predictions at threshold.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>accuracy (float): accuracy of predictions at threshold\n</code></pre>"},{"location":"medicalai/modelStats/#get_prevalence","title":"get_prevalence","text":"<pre><code>get_prevalence(expected)\n</code></pre> <p>Compute accuracy of predictions at threshold.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\n</code></pre> <p>Returns:</p> <pre><code>prevalence (float): prevalence of positive cases\n</code></pre>"},{"location":"medicalai/modelStats/#get_sensitivity","title":"get_sensitivity","text":"<pre><code>get_sensitivity(expected, preds, threshold=0.5)\n</code></pre> <p>Compute sensitivity of predictions at threshold.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>sensitivity (float): probability that our test outputs positive given that the case is actually positive\n</code></pre>"},{"location":"medicalai/modelStats/#get_specificity","title":"get_specificity","text":"<pre><code>get_specificity(expected, preds, threshold=0.5)\n</code></pre> <p>Compute specificity of predictions at threshold.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>specificity (float): probability that the test outputs negative given that the case is actually negative\n</code></pre>"},{"location":"medicalai/modelStats/#get_ppv","title":"get_ppv","text":"<pre><code>get_ppv(expected, preds, threshold=0.5)\n</code></pre> <p>Compute PPV of predictions at threshold.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>PPV (float): positive predictive value of predictions at threshold\n</code></pre>"},{"location":"medicalai/modelStats/#get_npv","title":"get_npv","text":"<pre><code>get_npv(expected, preds, threshold=0.5)\n</code></pre> <p>Compute NPV of predictions at threshold.</p> <p>Args:</p> <pre><code>expected (np.array): ground truth, size (n_examples)\npreds (np.array): model output, size (n_examples)\nthreshold (float): cutoff value for positive prediction from model\n</code></pre> <p>Returns:</p> <pre><code>NPV (float): negative predictive value of predictions at threshold\n</code></pre>"},{"location":"medicalai/modelStats/#compute_class_freqs","title":"compute_class_freqs","text":"<pre><code>compute_class_freqs(labels)\n</code></pre> <p>Compute positive and negative frequences for each class.</p> <p>Args:</p> <pre><code>labels (np.array): matrix of labels, size (num_examples, num_classes)\n</code></pre> <p>Returns:</p> <pre><code>positive_frequencies (np.array): array of positive frequences for each\n                                 class, size (num_classes)\nnegative_frequencies (np.array): array of negative frequences for each\n                                 class, size (num_classes)\n</code></pre>"},{"location":"medicalai/modelStats/#get_weighted_loss","title":"get_weighted_loss","text":"<pre><code>get_weighted_loss(pos_weights, neg_weights, epsilon=1e-07)\n</code></pre> <p>Return weighted loss function given negative weights and positive weights.</p> <p>Args:</p> <p>pos_weights (np.array): array of positive weights for each class, size (num_classes)   neg_weights (np.array): array of negative weights for each class, size (num_classes)</p> <p>Returns:</p> <p>weighted_loss (function): weighted loss function</p>"},{"location":"medicalai/modelStats/#generate_evaluation_report","title":"generate_evaluation_report","text":"<pre><code>generate_evaluation_report(CLASS_NAMES,\n                           predictions,\n                           groundTruth=None,\n                           generator=None,\n                           returnPlot=True,\n                           showPlot=True,\n                           printStat=True,\n                           **kwargs)\n</code></pre> <p>Generates Evaluation PDF Report for a Test/Validation experimentation. Ground truth needs to be passed to generate the pdf report.</p> <p>Args:</p> <pre><code>CLASS_NAMES (list): List of Label names or class names of dataset.\npredictions (np.array): Predicted output of test data.\ngroundTruth (np.array): Ground truth of test data.\ngenerator (Optional): If generator method used in training, pass the generator.\nreturnPlot (Bool): Returns the plot handle if set to `True`\nshowPlot (Bool): Display the plot if set to `True`. [IMP: Until the plot is closed, the code execution is blocked.]\nprintStat (Bool): Print the statistics of the experiment on the console if set to `True`. T\n**kwargs (Optional): Plot Setting Arguments\n</code></pre> <p>Returns:</p> <pre><code>true_pos (int): true positives\n</code></pre>"},{"location":"medicalai/modules/","title":"medicalai","text":"<ul> <li> <p>medicalai package</p> <ul> <li> <p>Subpackages</p> <ul> <li> <p>medicalai.chief package</p> <ul> <li> <p>Subpackages</p> </li> <li> <p>Submodules</p> </li> <li> <p>medicalai.chief.core module</p> </li> <li> <p>medicalai.chief.dataset_prepare module</p> </li> <li> <p>medicalai.chief.download_utils module</p> </li> <li> <p>medicalai.chief.networks module</p> </li> <li> <p>medicalai.chief.prettyloss module</p> </li> <li> <p>medicalai.chief.uFuncs module</p> </li> <li> <p>Module contents</p> </li> </ul> </li> </ul> </li> <li> <p>Module contents</p> </li> </ul> </li> </ul>"},{"location":"medicalai/networks/","title":"medicalai.chief.networks","text":""},{"location":"medicalai/networks/#networkinit","title":"NetworkInit","text":"<p><pre><code>NetworkInit()\n</code></pre> Base class for parameter Network initializers.</p> <p>The :class:<code>NetworkInit</code> class represents a network initializer used to initialize network/model parameters for numerous medical ai networks. It should be subclassed when implementing new types of network initializers.</p>"},{"location":"medicalai/networks/#call","title":"call","text":"<p><pre><code>NetworkInit.call(inputSize, OutputSize, convLayers=None)\n</code></pre> Sample should return model initialized with input and output Sizes.</p>"},{"location":"medicalai/networks/#parameters","title":"Parameters","text":"<p>inputSize : tuple or int.     Integer or tuple specifying the input of network.</p> <p>OutputSize : tuple or int.     Integer or tuple specifying the output classes of network.</p>"},{"location":"medicalai/networks/#returns","title":"Returns","text":"<p>numpy.array.     Initialized Model.</p>"},{"location":"medicalai/networks/#tinymednet","title":"tinyMedNet","text":"<p><pre><code>tinyMedNet()\n</code></pre> tinyMedNet is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.</p>"},{"location":"medicalai/networks/#tinymednet_v2","title":"tinyMedNet_v2","text":"<p><pre><code>tinyMedNet_v2()\n</code></pre> tinyMedNet_v2 allows users to configure the number of Conv/CNN layers. tinyMedNet_v2 is a classification network that consumes very less resources and can be trained even on CPUs. This network can be used to demonstrate the framework working. Additionally this acts a starting point for example/tutorial for getting started to know the Medical AI library.</p>"},{"location":"medicalai/networks/#tinymednet_v3","title":"tinyMedNet_v3","text":"<p><pre><code>tinyMedNet_v3()\n</code></pre> tinyMedNet_v3 has 3 FC layers with Dropout and Configurable number of Conv/CNN Layers.</p>"},{"location":"medicalai/networks/#resnet20","title":"resNet20","text":"<p><pre><code>resNet20()\n</code></pre> resnet20</p>"},{"location":"medicalai/networks/#resnet32","title":"resNet32","text":"<p><pre><code>resNet32()\n</code></pre> resnet32</p>"},{"location":"medicalai/networks/#resnet56","title":"resNet56","text":"<p><pre><code>resNet56()\n</code></pre> RESNET56</p>"},{"location":"medicalai/networks/#resnet110","title":"resNet110","text":"<p><pre><code>resNet110()\n</code></pre> resnet110</p>"},{"location":"medicalai/networks/#meganet","title":"megaNet","text":"<pre><code>megaNet()\n</code></pre> <p>megaNet is based on COVID-NET. This is a tensorflow 2.0 network variant for COVID-Net described in Paper \"COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images\" by Linda Wang et al. Reference: https://github.com/busyyang/COVID-19/</p>"},{"location":"medicalai/networks/#densenet121","title":"DenseNet121","text":"<pre><code>DenseNet121()\n</code></pre> <p>DenseNet121 model, with weights pre-trained on ImageNet inputSize: input image size tuple outputSize: Number of classes for prediction</p>"},{"location":"medicalai/networks/#vgg16","title":"VGG16","text":"<pre><code>VGG16()\n</code></pre> <p>VGG16 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/networks/#mobilenet","title":"MobileNet","text":"<pre><code>MobileNet()\n</code></pre> <p>MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/networks/#mobilenetv2","title":"MobileNetV2","text":"<pre><code>MobileNetV2()\n</code></pre> <p>MobileNet model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/networks/#xception","title":"Xception","text":"<pre><code>Xception()\n</code></pre> <p>Xception model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/networks/#inceptionv3","title":"InceptionV3","text":"<pre><code>InceptionV3()\n</code></pre> <p>InceptionV3 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/networks/#inceptionresnetv2","title":"InceptionResNetV2","text":"<pre><code>InceptionResNetV2()\n</code></pre> <p>InceptionResNetV2 model, with weights pre-trained on ImageNet inputSize: input image size tuple,default : (224,223,3) outputSize: Number of classes for prediction</p>"},{"location":"medicalai/examples/train_unet_image_segmentation/","title":"Example: Image Segmentation (Cell Membrane)","text":"<p>The library currently supports binary segmentation only. The dataset to perform imgage segmentation can be downloaded from here</p>"},{"location":"medicalai/examples/train_unet_image_segmentation/#import-libraries","title":"Import libraries","text":"<pre><code>import os\nimport medicalai as ai\nimport tensorflow as tf\n</code></pre>"},{"location":"medicalai/examples/train_unet_image_segmentation/#define-the-hyperparameters","title":"Define the hyperparameters","text":"<p>Specify the dataset folder which further contains test &amp; train folders each with n class object folders <pre><code>datasetFolderPath = \"../data/membrane\"\n</code></pre> Specify the dimensions of image to be fed to network <pre><code>(IMG_HEIGHT,IMG_WIDTH) = (256,256)\n</code></pre> Specify the name of the model to be trained on <pre><code>EXPT_NAME = '1'\nAI_NAME = 'unet' \nMODEL_SAVE_NAME = '../model/'+AI_NAME+'/Medical_RSNA_'+str(IMG_HEIGHT)+'x'+str(IMG_WIDTH)+'_'+AI_NAME+'_EXPT_'+str(EXPT_NAME)\n</code></pre> Specify remaining hyperparamters <pre><code>batch_size = 32\nepochs = 10\nlearning_rate = 0.0001\n</code></pre></p>"},{"location":"medicalai/examples/train_unet_image_segmentation/#define-the-augmentation-for-the-generator","title":"Define the augmentation for the generator","text":"<p><pre><code>augment = ai.AUGMENTATION(rotation_range = 12, \n                          fill_mode='nearest', \n                          width_shift_range=0.1, \n                          height_shift_range=0.1, \n                          brightness_range = (0.9, 1.1), \n                          zoom_range=(0.85, 1.15), \n                          rescale= 1./255)\n</code></pre> Load your data from folder using datasetGenFromFolder if your data is in folder structured form <pre><code>dsHandler = ai.segmentaionGenerator(folder=datasetFolderPath,targetDim=(IMG_HEIGHT,IMG_WIDTH), \n                                        augmentation=augment, class_mode=None,\n                                        batch_size = 1,color_mode=\"grayscale\",\n                                        image_folder_name = \"image\", mask_folder_name = \"label\")\n</code></pre> <pre><code>trainGen = dsHandler.load_train_generator()\ntestGen = dsHandler.load_test_generator()\n</code></pre></p>"},{"location":"medicalai/examples/train_unet_image_segmentation/#train-model","title":"Train model","text":"<p>Now our image generator is ready to be trained on our model. But first we need to define a tensorflow callback for the model <pre><code>model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n                                        MODEL_SAVE_NAME+'best.h5', \n                                        verbose=0,\n                                        mode='auto', \n                                        save_freq=5,\n                                        save_best_only=True,\n                                        )\ncallbacks = [model_checkpoint]\n</code></pre> <pre><code>trainer = ai.TRAIN_ENGINE()\ntrainer.train_and_save_segmentation(AI_NAME=AI_NAME,\n                                    MODEL_SAVE_NAME = MODEL_SAVE_NAME, \n                                    trainSet=trainGen,inputSize = (256,256,1),\n                                    BATCH_SIZE= BATCH_SIZE, EPOCHS= EPOCHS, \n                                    LEARNING_RATE= LEARNING_RATE, SAVE_BEST_MODEL = SAVE_BEST_MODEL, \n                                    BEST_MODEL_COND= BEST_MODEL_COND, callbacks = None,\n                                    convLayers= convLayers, showModel = False\n\n                           )\n</code></pre> Use the above model to predict segmentation masks <pre><code>infEngine = ai.INFERENCE_ENGINE(MODEL_SAVE_NAME)\npredsG = infEngine.predict_segmentation(testGen)\n</code></pre> Save the predicted segmentation masks in a folder <pre><code>infEngine.saveResult(save_path='results',npyfile=predsG)\n</code></pre> </p>"},{"location":"medicalai/examples/train_unet_multilabel-segmentation/","title":"Example: Image Segmentation (Camvid Dataset)","text":"<p>The dataset to perform imgage segmentation can be downloaded from here</p>"},{"location":"medicalai/examples/train_unet_multilabel-segmentation/#import-libraries","title":"Import libraries","text":"<pre><code>import os\nimport numpy as np\nimport medicalai as ai\nimport tensorflow as tf\n</code></pre>"},{"location":"medicalai/examples/train_unet_multilabel-segmentation/#define-the-hyperparameters","title":"Define the hyperparameters","text":"<p>Specify the dataset folder which further contains test &amp; train folders each with n class object folders <pre><code>datasetFolderPath = \"../data/camvid/\"\n</code></pre> Specify the dimensions of image to be fed to network <pre><code>(IMG_HEIGHT,IMG_WIDTH) = (256,256)\n</code></pre> Specify the name of the model to be trained on <pre><code>EXPT_NAME = '1'\nAI_NAME = 'unet' \nMODEL_SAVE_NAME = '../model/'+AI_NAME+'/Medical_RSNA_'+str(IMG_HEIGHT)+'x'+str(IMG_WIDTH)+'_'+AI_NAME+'_EXPT_'+str(EXPT_NAME)\n</code></pre> Specify remaining hyperparamters <pre><code>batch_size = 32\nepochs = 10\nlearning_rate = 0.0001\n</code></pre></p>"},{"location":"medicalai/examples/train_unet_multilabel-segmentation/#define-the-augmentation-for-the-generator","title":"Define the augmentation for the generator","text":"<p>(The following augmentation is for image only) <pre><code>augment = ai.AUGMENTATION(rescale= 1./255)\n</code></pre> Load your data from folder using datasetGenFromFolder if your data is in folder structured form. Make sure <code>flag_multi_class</code> is set to <code>True</code> <pre><code>dsHandler = ai.segmentaionGenerator(folder=datasetFolderPath,targetDim=(IMG_HEIGHT,IMG_WIDTH), \n                                        augmentation=augment, class_mode=None,\n                                        batch_size = batch_size,\n                                        image_folder_name = \"image\", mask_folder_name = \"masks\",\n                                        flag_multi_class=True)\n</code></pre> <pre><code>trainGen = dsHandler.load_train_generator()\ntestGen = dsHandler.load_test_generator()\n</code></pre></p>"},{"location":"medicalai/examples/train_unet_multilabel-segmentation/#train-model","title":"Train model","text":"<p>Now our image generator is ready to be trained on our model. But first we need to define a tensorflow callback for the model <pre><code>model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n                                        MODEL_SAVE_NAME+'best.h5', \n                                        verbose=0,\n                                        mode='auto', \n                                        save_freq=5,\n                                        save_best_only=True,\n                                        )\ncallbacks = [model_checkpoint]\n</code></pre> <pre><code>TRAIN_STEPS = int(np.ceil(dsHandler.imageGen.generator.n/dsHandler.batch_size))\ntrainer = ai.TRAIN_ENGINE()\ntrainer.train_and_save_segmentation(AI_NAME=AI_NAME,\n                                    MODEL_SAVE_NAME = MODEL_SAVE_NAME, \n                                    trainSet=trainGen,inputSize = (IMG_HEIGHT,IMG_WIDTH,3),\n                                    TRAIN_STEPS=TRAIN_STEPS,\n                                    BATCH_SIZE= BATCH_SIZE, EPOCHS= EPOCHS, \n                                    LEARNING_RATE= LEARNING_RATE, SAVE_BEST_MODEL = SAVE_BEST_MODEL, \n                                    callbacks = callbacks,\n                                    showModel = False)\n</code></pre> Use the above model to predict segmentation masks <pre><code>infEngine = ai.INFERENCE_ENGINE(MODEL_SAVE_NAME)\npredsG = infEngine.predict_segmentation(testGen)\n</code></pre> Save the predicted segmentation masks in a folder <pre><code>infEngine.saveResult(save_path='results',npyfile=predsG,num_class=32,flag_multi_class=True)\n</code></pre></p>"},{"location":"medicalai/examples/train_using_generator_dataset/","title":"Example 1: Train your model using medicalai generator","text":"<pre><code>import os\nimport medicalai as ai\nimport tensorflow as tf\n</code></pre>"},{"location":"medicalai/examples/train_using_generator_dataset/#define-the-hyperparameters","title":"Define the hyperparameters","text":"<p>Specify the dataset folder which further contains test &amp; train folders each with n class object folders <pre><code>datasetFolderPath = \"../data\"\n</code></pre> Specify the dimensions of image to be fed to network <pre><code>IMG_HEIGHT = 224\nIMG_WIDTH = 224\n</code></pre> Specify the number of classes for classification <pre><code>OUTPUT_CLASSES = 3\n</code></pre> Specify the name of the model to be trained on <pre><code>EXPT_NAME = '1'\nAI_NAME = 'mobilenet' \nMODEL_SAVE_NAME = '../model/'+AI_NAME+'/Medical_RSNA_'+str(IMG_HEIGHT)+'x'+str(IMG_WIDTH)+'_'+AI_NAME+'_EXPT_'+str(EXPT_NAME)\n</code></pre> Specify remaining hyperparamters <pre><code>batch_size = 32\nepochs = 10\nlearning_rate = 0.0001\n</code></pre></p>"},{"location":"medicalai/examples/train_using_generator_dataset/#define-the-augmentation-for-the-generator","title":"Define the augmentation for the generator","text":"<p><pre><code>augment = ai.AUGMENTATION(rotation_range = 12, \n                          fill_mode='nearest', \n                          width_shift_range=0.1, \n                          height_shift_range=0.1, \n                          brightness_range = (0.9, 1.1), \n                          zoom_range=(0.85, 1.15), \n                          rescale= 1./255,)\n</code></pre> - Load your data from folder using datasetGenFromFolder if your data is in folder structured form <pre><code>dsHandler = ai.datasetGenFromFolder(folder=datasetFolderPath,\n                                    targetDim=(IMG_HEIGHT,IMG_WIDTH), \n                                    augmentation=augment,\n                                    class_mode=\"categorical\"\n                                    normalize=False,\n                                    batch_size=batch_size,\n                                    augmentation=True,\n                                    color_mode='rgb', #if the images are of rgb channels else 'grayscale'\n                                    class_mode='categorical',\n                                    shuffle=True,\n                                    seed=23))\n\ntrainGen, testGen = dsHandler.load_generator()\n</code></pre> - Incase your data is not in folder structured form but rather details embeded in a csv file, use the datasetGenFromDataframe method to load data to generator instead of datasetGenFromFolder <pre><code>dsHandler = ai.datasetGenFromDataframe( folder = datasetFolderPath, #folder containg train and test folders\n                                        csv_path='.', #path to train.cvs and test.csv\n                                        x_col='name', \n                                        y_col='labels',\n                                        targetDim=(IMG_HEIGHT,IMG_WIDTH), \n                                        normalize=False,\n                                        batch_size=batch_size,\n                                        augmentation=True,\n                                        color_mode='rgb',\n                                        class_mode='sparse',\n                                        shuffle=True,\n                                        seed=23\n                                        )\ntrainGen, testGen = dsHandler.load_generator()\n</code></pre></p>"},{"location":"medicalai/examples/train_using_generator_dataset/#train-model","title":"Train model","text":"<p>Now our image generator is ready to be trained on our model. But first we need to define a tensorflow callback for the model <pre><code>model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n                                        MODEL_SAVE_NAME+'best.h5', \n                                        verbose=0,\n                                        mode='auto', \n                                        save_freq=5,\n                                        save_best_only=True,\n                                        )\ncallbacks = [model_checkpoint]\n</code></pre> <pre><code>trainer = ai.TRAIN_ENGINE()\ntrainer.train_and_save_model(AI_NAME=AI_NAME,\n                             MODEL_SAVE_NAME = MODEL_SAVE_NAME, \n                             trainSet=trainGen, testSet=testGen,\n                             OUTPUT_CLASSES=OUTPUT_CLASSES, \n                             RETRAIN_MODEL= True,\n                             BATCH_SIZE= batch_size,\n                             EPOCHS= epochs, \n                             LEARNING_RATE= learning_rate,\n                             SAVE_BEST_MODEL = True, \n                             callbacks = callbacks,\n                             convLayers= None,\n                             loss='categorical_crossentropy',\n                                           showModel = False #mark this True if you want to see model summary\n                             )\n</code></pre> - Use the above model to predict <pre><code>test_x,test_y = dsHandler.get_numpy(testGen)\npredsG = trainer.predict(test_x)\n</code></pre> - Generate evaluation report <pre><code>trainer.generate_evaluation_report(testGen,predictions = predsG)\n</code></pre></p>"},{"location":"medicalai/examples/train_using_numpy_dataset/","title":"Example 1: IMAGE Recognition/Classification","text":""},{"location":"medicalai/examples/train_using_numpy_dataset/#train-an-ai-model-using-medicalais-numpy-dataset-processor","title":"Train an AI model using medicalai's numpy dataset processor","text":"<pre><code>import os\nimport medicalai as ai\n</code></pre>"},{"location":"medicalai/examples/train_using_numpy_dataset/#download-sample-dataset","title":"Download sample Dataset","text":"<pre><code>datasetDWLD = ai.getFile('https://github.com/aibharata/covid19-dataset/archive/v1.0.zip', subDir='dataset')\ndatasetFolderPath = datasetDWLD+'/covid19-dataset-1.0/chest-xray-pnumonia-covid19/'\n</code></pre>"},{"location":"medicalai/examples/train_using_numpy_dataset/#define-the-hyperparameters-of-dataset-processor","title":"Define the hyperparameters of Dataset Processor","text":"<p>A. Specify the dimensions of image to be fed to network <pre><code>IMG_HEIGHT = 64\nIMG_WIDTH = 64\nOUTPUT_CLASSES = 3 \n</code></pre></p>"},{"location":"medicalai/examples/train_using_numpy_dataset/#process-your-dataset-using-numpy-based-datasetfromfolder-class","title":"Process your dataset using Numpy based <code>datasetFromFolder</code> class.","text":"<p>The <code>datasetFromFolder</code> class takes a folder path where your dataset is located. This folder should have <code>test</code> and <code>train</code> folders.  Each of the folder should have the class sub-folder for your classification problem. <pre><code>trainSet,testSet,labelNames =ai.datasetFromFolder(datasetFolderPath, targetDim = (IMG_WIDTH,IMG_WIDTH)).load_dataset()\n\n# Print shapes of the loaded test and train data\nprint('TrainSet Data Shape: {:}; TrainSet Labels Shape:{:}'.format(testSet.data.shape,testSet.labels.shape))\nprint('TrainSet Data Shape: {:}; TrainSet Labels Shape:{:}'.format(testSet.data.shape,testSet.labels.shape))\n</code></pre></p>"},{"location":"medicalai/examples/train_using_numpy_dataset/#define-the-hyperparameters-of-training","title":"Define the hyperparameters of Training","text":"<p>A. Specify training hyperparamters <pre><code>batch_size = 32\nepochs = 10\nlearning_rate = 0.0001\n</code></pre> B. Specify the model name to save/retrain <pre><code>MODEL_SAVE_NAME = 'medicalai_test_model_1'\n</code></pre> C. Choose from the prebuilt networks from Medicalai Library. You can also pass a class with your own custom network to <code>AI_NAME</code> parameter. <pre><code>AI_NAME = 'tinyMedNet'\n</code></pre></p>"},{"location":"medicalai/examples/train_using_numpy_dataset/#initialize-train_engine-and-start-training","title":"Initialize TRAIN_ENGINE and Start Training","text":"<pre><code>trainer = ai.TRAIN_ENGINE()\ntrainer.train_and_save_model(AI_NAME=AI_NAME,\n                             MODEL_SAVE_NAME = MODEL_SAVE_NAME, \n                             trainSet=trainGen, testSet=testGen,\n                             OUTPUT_CLASSES=OUTPUT_CLASSES, \n                             RETRAIN_MODEL= True,\n                             BATCH_SIZE= batch_size,\n                             EPOCHS= epochs, \n                             LEARNING_RATE= learning_rate,\n                             SAVE_BEST_MODEL = True,\n                             showModel = True # Set this True if you want to see model summary\n                             )\n</code></pre>"},{"location":"medicalai/examples/train_using_numpy_dataset/#view-and-save-training-stats","title":"View and Save Training Stats","text":"<p>Plot training accuracy and loss w.r.t to epochs</p> <pre><code>trainer.plot_train_acc_loss()\n</code></pre>"},{"location":"medicalai/examples/train_using_numpy_dataset/#generate-evaluation-report-for-trained-model","title":"Generate evaluation report for Trained Model","text":"<pre><code>trainer.generate_evaluation_report(testSet)\n</code></pre>"},{"location":"medicalai/examples/train_using_numpy_dataset/#explain-the-model-for-a-input-sample","title":"Explain the model for a input sample","text":"<pre><code>trainer.explain(testSet.data[0:1], layer_to_explain='CNN3', classNames = labelNames)\n</code></pre>"}]}